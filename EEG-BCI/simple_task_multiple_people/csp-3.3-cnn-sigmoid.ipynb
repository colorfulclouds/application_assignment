{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = 128 #hz\n",
    "trial_time = 3 #s\n",
    "\n",
    "origin_channel = 5 #5 channel eeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cov_mat(X):\n",
    "    return np.matmul(X , X.T)/np.trace(np.matmul(X , X.T))\n",
    "\n",
    "#计算每种样本的平均协方差矩阵\n",
    "def average_norm_cov_mat(data):\n",
    "    count = data.shape[0]\n",
    "    sum_mat = np.zeros(shape=(data[0].shape[0] , data[0].shape[0]))\n",
    "    \n",
    "    for i in range(count):\n",
    "        sum_mat += cov_mat(data[i])\n",
    "    \n",
    "    return sum_mat/count\n",
    "\n",
    "def load_data(file_name):\n",
    "    #pink and white\n",
    "    \n",
    "    temp = pd.read_csv(file_name)\n",
    "    \n",
    "    #删除前3秒和后2秒数据\n",
    "    temp = temp.iloc[ : temp.shape[0] - 2*128] #后2秒 2s sample:128hz\n",
    "    temp = temp.iloc[3*128 : ] #前3秒 3s sample:128hz\n",
    "    \n",
    "    for column in temp.columns:\n",
    "        temp[column] = (temp[column] - temp[column].mean())/temp[column].std() #norm\n",
    "    \n",
    "    #5 channels data\n",
    "    return temp[['AF3' , 'T7','Pz' , 'T8' , 'AF4']]\n",
    "\n",
    "def sep(one_data , label):\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    \n",
    "    size = sample*trial_time #384\n",
    "    \n",
    "    for i in range(one_data.shape[0] - size):\n",
    "        train_data.append(one_data.iloc[i : i+size].values) #add one train sample\n",
    "        train_labels.append(label) #corresponding label\n",
    "    \n",
    "    return train_data , train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_eeg_csv(file_names):\n",
    "    #concat a big csv file\n",
    "    first_file = load_data(file_name = file_names[0])\n",
    "    \n",
    "    file_names.remove(file_names[0])\n",
    "    \n",
    "    for file_name in file_names:\n",
    "        first_file = first_file.append(load_data(file_name = file_name) , ignore_index = True)\n",
    "    \n",
    "    return first_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#low pass filter\n",
    "#50Hz\n",
    "\n",
    "def low_pass(data):\n",
    "    point = 50 #highest freq = 50hz\n",
    "    length = sample * trial_time #256\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            a = np.fft.fft(data[i][j]).real\n",
    "            b = np.fft.fft(data[i][j]).imag\n",
    "            a[point : length-point] = 0\n",
    "            b[point : length-point] = 0\n",
    "            #重建频谱\n",
    "            new_freq = [np.complex(a[i] , b[i]) for i in range(length)]\n",
    "            new_freq = np.array(new_freq)\n",
    "            \n",
    "            data[i][j] = np.fft.ifft(new_freq)\n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用白色\n",
    "data_1 = concat_eeg_csv(['data/train_1/fei_white_1.csv' , 'data/train_1/fei_white_2.csv'])\n",
    "data_2 = concat_eeg_csv(['data/train_1/sen_white_1.csv' , 'data/train_1/sen_white_2.csv'])\n",
    "\n",
    "#使用粉色\n",
    "#data_1 = concat_eeg_csv(['data/train_1/fei_pink_1.csv' , 'data/train_1/fei_pink_2.csv'])\n",
    "#data_2 = concat_eeg_csv(['data/train_1/sen_pink_1.csv' , 'data/train_1/sen_pink_2.csv'])\n",
    "\n",
    "#为了使用sigmoid激活函数 需要将标签调整为0和1\n",
    "train_data_1 , train_labels_1 = sep(data_1 , 0)\n",
    "train_data_2 , train_labels_2 = sep(data_2 , 1)\n",
    "\n",
    "train_data_1 = np.array(train_data_1)\n",
    "train_data_2 = np.array(train_data_2)\n",
    "\n",
    "train_labels_1 = np.array(train_labels_1)\n",
    "train_labels_2 = np.array(train_labels_2)\n",
    "\n",
    "train_data_1 = np.transpose(train_data_1 , axes=(0 , 2 , 1))\n",
    "train_data_2 = np.transpose(train_data_2 , axes=(0 , 2 , 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7752, 5, 384) (18980, 5, 384)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_1.shape , train_data_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:18: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "#=============\n",
    "#滤波阶段 此时一个小样本为3秒的数据量  此时大致认为信号为平稳的\n",
    "#train_data_1 = low_pass(train_data_1)\n",
    "#train_data_2 = low_pass(train_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate((train_data_1 , train_data_2))\n",
    "\n",
    "train_labels = np.concatenate((train_labels_1 , train_labels_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26732, 5, 384) (26732,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape , train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用CNN进行处理\n",
    "#最后的输出设置为1个输出单元 激活为sigmoid\n",
    "#========\n",
    "#========\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout , Conv2D , MaxPooling2D , Reshape , BatchNormalization , Flatten\n",
    "from keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#增加一维 作为last channel 满足卷积要求\n",
    "train_data = train_data[:,:,:, np.newaxis] # [None,origin channel,EEG length,artificial channel]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26732, 5, 384, 1) (26732,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape , train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = np.transpose(train_data , axes=(0 , 2 , 1 , 3)) #[None,EEG length,origin_channel,artificial channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26732, 384, 5, 1) (26732,)\n"
     ]
    }
   ],
   "source": [
    "#print(train_data.shape , train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = 0.5\n",
    "\n",
    "model = Sequential()\n",
    "#sample*trial_time=384\n",
    "#网络输入为384维\n",
    "\n",
    "#CNNs需要的输入的样本集 形式为（样本数量，5,384，1）5为原始特征数量 1为人为增加的通道\n",
    "\n",
    "#conv pool 1\n",
    "model.add(Conv2D(filters=60 , kernel_size=(1,4) , strides=(1,3) , padding='valid' , activation='elu' , input_shape=(origin_channel , sample*trial_time , 1) , name='conv1'))\n",
    "model.add(MaxPooling2D(pool_size=(1,2) , strides=(1,2) , padding='valid' , name='pool1'))\n",
    "#dropout\n",
    "model.add(Dropout(1 - keep_prob , name='dropout1'))\n",
    "#batch norm\n",
    "model.add(BatchNormalization(name='batch-norm1'))\n",
    "\n",
    "#conv pool 2\n",
    "model.add(Conv2D(60 , kernel_size=(1,4) , strides=(1,3) , padding='valid' , activation='elu' , kernel_regularizer=l2() , name='conv2'))\n",
    "model.add(MaxPooling2D(pool_size=(1,2) , strides=(1,2) , padding='valid' , name='pool2'))\n",
    "#dropout\n",
    "model.add(Dropout(1 - keep_prob , name='dropout2'))\n",
    "#batch norm\n",
    "model.add(BatchNormalization(name='batch-norm2'))\n",
    "\n",
    "#conv 3\n",
    "model.add(Conv2D(60 , kernel_size=(1,4) , strides=(1,3) , padding='valid' , activation='elu' , kernel_regularizer=l2() , name='conv3'))\n",
    "#no pooling\n",
    "#dropout\n",
    "model.add(Dropout(1 - keep_prob , name='dropout3'))\n",
    "#batch norm\n",
    "model.add(BatchNormalization(name='batch-norm3'))\n",
    "\n",
    "#conv pool 4\n",
    "model.add(Conv2D(90 , kernel_size=(1,3) , strides=(1,1) , padding='same' , activation='elu' , kernel_regularizer=l2() , name='conv4'))\n",
    "model.add(MaxPooling2D(pool_size=(1,2) , strides=(1,2) , padding='valid' , name='pool4'))\n",
    "#dropout\n",
    "model.add(Dropout(1 - keep_prob , name='dropout4'))\n",
    "#batch norm\n",
    "model.add(BatchNormalization(name='batch-norm4'))\n",
    "\n",
    "#conv pool 5\n",
    "model.add(Conv2D(120 , kernel_size=(1,3) , strides=(1,1) , padding='same' , activation='elu' , kernel_regularizer=l2() , name='conv5'))\n",
    "#model.add(MaxPooling2D(pool_size=(1,2) , strides=(1,2) , padding='valid' , name='pool5'))\n",
    "#dropout\n",
    "model.add(Dropout(1 - keep_prob , name='dropout5'))\n",
    "#batch norm\n",
    "model.add(BatchNormalization(name='batch-norm5'))\n",
    "\n",
    "#flatten\n",
    "model.add(Flatten(name='flatten'))\n",
    "\n",
    "#fc\n",
    "model.add(Dense(units=256 , activation='elu' , name='fc1'))\n",
    "model.add(Dense(units=128 , activation='elu' , name='fc2'))\n",
    "model.add(Dense(units=64 , activation='elu' , name='fc3'))\n",
    "model.add(Dense(units=32 , activation='elu' , name='f4'))\n",
    "model.add(Dense(units=8 , activation='elu' , name='fc5'))\n",
    "\n",
    "#fc last layer\n",
    "model.add(Dense(units=1 , activation='sigmoid' , name='fc6'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 5, 127, 60)        300       \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 5, 63, 60)         0         \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 5, 63, 60)         0         \n",
      "_________________________________________________________________\n",
      "batch-norm1 (BatchNormalizat (None, 5, 63, 60)         240       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 5, 20, 60)         14460     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 5, 10, 60)         0         \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 5, 10, 60)         0         \n",
      "_________________________________________________________________\n",
      "batch-norm2 (BatchNormalizat (None, 5, 10, 60)         240       \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 5, 3, 60)          14460     \n",
      "_________________________________________________________________\n",
      "dropout3 (Dropout)           (None, 5, 3, 60)          0         \n",
      "_________________________________________________________________\n",
      "batch-norm3 (BatchNormalizat (None, 5, 3, 60)          240       \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 5, 3, 90)          16290     \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 5, 1, 90)          0         \n",
      "_________________________________________________________________\n",
      "dropout4 (Dropout)           (None, 5, 1, 90)          0         \n",
      "_________________________________________________________________\n",
      "batch-norm4 (BatchNormalizat (None, 5, 1, 90)          360       \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 5, 1, 120)         32520     \n",
      "_________________________________________________________________\n",
      "dropout5 (Dropout)           (None, 5, 1, 120)         0         \n",
      "_________________________________________________________________\n",
      "batch-norm5 (BatchNormalizat (None, 5, 1, 120)         480       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               153856    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "f4 (Dense)                   (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "fc5 (Dense)                  (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 276,951\n",
      "Trainable params: 276,171\n",
      "Non-trainable params: 780\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam' , loss='binary_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.6415 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a7949502b0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data[0,np.newaxis] , train_labels[0 , np.newaxis] , batch_size=1 , epochs=1)# , validation_data=(val_data_features , val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==============\n",
    "#==============\n",
    "#val step\n",
    "#使用验证集进行测试\n",
    "#白色\n",
    "data_1_val = load_data('data/val_1/fei_white_3.csv')\n",
    "data_2_val = load_data('data/val_1/sen_white_3.csv')\n",
    "\n",
    "#粉色\n",
    "#data_1_val = load_data('data/val_1/fei_pink_3.csv')\n",
    "#data_2_val = load_data('data/val_1/sen_pink_3.csv')\n",
    "\n",
    "val_data_1 , val_labels_1 = sep(data_1_val , 0)\n",
    "val_data_2 , val_labels_2 = sep(data_2_val , 1)\n",
    "\n",
    "val_data_1 = np.array(val_data_1)\n",
    "val_data_2 = np.array(val_data_2)\n",
    "\n",
    "val_labels_1 = np.array(val_labels_1)\n",
    "val_labels_2 = np.array(val_labels_2)\n",
    "\n",
    "val_data_1 = np.transpose(val_data_1 , axes=(0 , 2 , 1))\n",
    "val_data_2 = np.transpose(val_data_2 , axes=(0 , 2 , 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#================\n",
    "#验证集滤波 依次进行\n",
    "#val_data_1 = low_pass(val_data_1)\n",
    "#val_data_2 = low_pass(val_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#===================\n",
    "#concat\n",
    "val_data = np.concatenate((val_data_1 , val_data_2))\n",
    "\n",
    "val_labels = np.concatenate((val_labels_1 , val_labels_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12877, 5, 384) (12877,)\n"
     ]
    }
   ],
   "source": [
    "print(val_data.shape , val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_data = val_data[:,:,:, np.newaxis] # [None,origin channel,EEG length,artificial channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12877, 5, 384, 1) (12877,)\n"
     ]
    }
   ],
   "source": [
    "print(val_data.shape , val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 318ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.5816268920898438, 1.0]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss accu\n",
    "model.evaluate(val_data[0 , np.newaxis] , val_labels[0 , np.newaxis] , batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48345894]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.predict(val_data[0 , np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.5959973335266113, 1.0]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_data[0 , np.newaxis] , train_labels[0 , np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

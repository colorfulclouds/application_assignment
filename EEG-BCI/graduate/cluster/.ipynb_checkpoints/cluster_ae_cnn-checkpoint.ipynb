{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "import seaborn as sns #绘制confusion matrix heatmap\n",
    "\n",
    "import os\n",
    "import scipy.io as sio\n",
    "\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "\n",
    "import tqdm\n",
    "import  time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore') #忽略警告\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "sample_rate = 256\n",
    "origin_channel = 16\n",
    "\n",
    "\n",
    "SAMPLE_CHANNEL = ['Pz' , 'PO3' , 'PO4' , 'O1' , 'O2' , 'Oz' , 'O9' , 'FP2' ,\n",
    "                  'C4' , 'C6' , 'CP3' , 'CP1' ,\n",
    "                  'CPZ' , 'CP2' , 'CP4' , 'PO8']\n",
    "\n",
    "LABEL2STR = {0:'sen' , 1:'hong' , 2:'zhao',\n",
    "             3:'fen' , 4:'xiao' , 5:'yu' , \n",
    "             6:'bin' , 7:'wang' , 8:'wei' , \n",
    "             9:'fei'}\n",
    "\n",
    "CLIP_FORWARD = 1 #首部裁掉时间\n",
    "CLIP_BACKWARD = 1 #尾部裁掉时间\n",
    "\n",
    "trial_time = 3 #segment second\n",
    "\n",
    "\n",
    "#是否进行归一化\n",
    "#reference:a study on performance increasing in ssvep based bci application\n",
    "#IS_NORMALIZE = True\n",
    "\n",
    "#是否进行滤波\n",
    "#IS_FILTER = False\n",
    "#EEG频率范围\n",
    "#reference:a study on performance increasing in ssvep based bci application\n",
    "LO_FREQ = 0.5\n",
    "HI_FREQ = 40\n",
    "\n",
    "#是否陷波\n",
    "#IS_NOTCH = False\n",
    "NOTCH_FREQ = 50 #陷波 工频\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "\n",
    "    data = sio.loadmat(file_name=filename)['data_received'] #length*16 matrix\n",
    "\n",
    "    data = data[CLIP_FORWARD * sample_rate : - CLIP_BACKWARD * sample_rate] #首部 尾部 进行裁剪\n",
    "   \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(data , label , overlap_length):\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "\n",
    "    size = sample_rate * trial_time #一小段 256*3 个数据点\n",
    "    data_length = data.shape[0]\n",
    "\n",
    "    idx = 0\n",
    "    \n",
    "    while idx<=data_length-size:\n",
    "        train_data.append(data[idx : idx+size , :])\n",
    "        train_labels.append(label)\n",
    "\n",
    "        idx = idx + (size - overlap_length)\n",
    "        \n",
    "    return np.array(train_data) , np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_t_v(filenames):\n",
    "    # np.random.shuffle(filenames)\n",
    "    \n",
    "    return np.random.choice(filenames , size=10) #20次的计算准确率中 每次随机选择10个样本进行训练测试\n",
    "\n",
    "def combine(freq):    \n",
    "    overlap_length = 2*256 #重叠2秒数据\n",
    "    \n",
    "    #保证随机性 进行置乱\n",
    "    person_0_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/0/' % freq) )\n",
    "    person_1_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/1/' % freq) )\n",
    "    person_2_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/2/' % freq) )\n",
    "    person_3_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/3/' % freq) )\n",
    "    person_4_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/4/' % freq) )\n",
    "    person_5_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/5/' % freq) )\n",
    "    person_6_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/6/' % freq) )\n",
    "    person_7_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/7/' % freq) )\n",
    "    person_8_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/8/' % freq) )\n",
    "\n",
    "    #打开信号文件 并 合并\n",
    "    person_0 = np.concatenate([load_data('../incremental/data/base_rf/%s/0/' % freq + filename) for filename in person_0_filenames] , axis = 0)\n",
    "    person_1 = np.concatenate([load_data('../incremental/data/base_rf/%s/1/' % freq + filename) for filename in person_1_filenames] , axis = 0)\n",
    "    person_2 = np.concatenate([load_data('../incremental/data/base_rf/%s/2/' % freq + filename) for filename in person_2_filenames] , axis = 0)\n",
    "    person_3 = np.concatenate([load_data('../incremental/data/base_rf/%s/3/' % freq + filename) for filename in person_3_filenames] , axis = 0)\n",
    "    person_4 = np.concatenate([load_data('../incremental/data/base_rf/%s/4/' % freq + filename) for filename in person_4_filenames] , axis = 0)\n",
    "    person_5 = np.concatenate([load_data('../incremental/data/base_rf/%s/5/' % freq + filename) for filename in person_5_filenames] , axis = 0)\n",
    "    person_6 = np.concatenate([load_data('../incremental/data/base_rf/%s/6/' % freq + filename) for filename in person_6_filenames] , axis = 0)\n",
    "    person_7 = np.concatenate([load_data('../incremental/data/base_rf/%s/7/' % freq + filename) for filename in person_7_filenames] , axis = 0)\n",
    "    person_8 = np.concatenate([load_data('../incremental/data/base_rf/%s/8/' % freq + filename) for filename in person_8_filenames] , axis = 0)\n",
    "    \n",
    "    #============\n",
    "    #训练数据分段\n",
    "    train_person_data_0 , train_person_labels_0 = separate(person_0 , label = 0 , overlap_length=overlap_length)\n",
    "    train_person_data_1 , train_person_labels_1 = separate(person_1 , label = 1 , overlap_length=overlap_length)\n",
    "    train_person_data_2 , train_person_labels_2 = separate(person_2 , label = 2 , overlap_length=overlap_length)\n",
    "    train_person_data_3 , train_person_labels_3 = separate(person_3 , label = 3 , overlap_length=overlap_length)\n",
    "    train_person_data_4 , train_person_labels_4 = separate(person_4 , label = 4 , overlap_length=overlap_length)\n",
    "    train_person_data_5 , train_person_labels_5 = separate(person_5 , label = 5 , overlap_length=overlap_length)\n",
    "    train_person_data_6 , train_person_labels_6 = separate(person_6 , label = 6 , overlap_length=overlap_length)\n",
    "    train_person_data_7 , train_person_labels_7 = separate(person_7 , label = 7 , overlap_length=overlap_length)\n",
    "    train_person_data_8 , train_person_labels_8 = separate(person_8 , label = 8 , overlap_length=overlap_length)\n",
    "\n",
    "    #合并数据\n",
    "    train_data = np.concatenate((train_person_data_0 , train_person_data_1 , train_person_data_2 ,\n",
    "                                 train_person_data_3 , train_person_data_4 , train_person_data_5 ,\n",
    "                                 train_person_data_6 , train_person_data_7 , train_person_data_8 ,\n",
    "                                 ))\n",
    "    \n",
    "    train_labels = np.concatenate((train_person_labels_0 , train_person_labels_1 , train_person_labels_2 ,\n",
    "                                   train_person_labels_3 , train_person_labels_4 , train_person_labels_5 ,\n",
    "                                   train_person_labels_6 , train_person_labels_7 , train_person_labels_8 ,\n",
    "                                    ))\n",
    "    \n",
    "    #产生索引并置乱\n",
    "    idx_train_data = list(range(train_data.shape[0]))\n",
    "    np.random.shuffle(idx_train_data)\n",
    "\n",
    "    #将训练数据置乱\n",
    "    train_data = train_data[idx_train_data]\n",
    "    train_labels = train_labels[idx_train_data]\n",
    "        \n",
    "    return train_data , train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_data_labels(session_id , freq , is_training):\n",
    "    if is_training:\n",
    "        overlap_length = 256*2\n",
    "    else:\n",
    "        overlap_length = 0\n",
    "    \n",
    "    str_freq = str(freq)\n",
    "    \n",
    "    subjcets = os.listdir('../incremental/data/incremental/%s/s%d/' % (str_freq , session_id)) #受试者ID\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for subjcet in subjcets:\n",
    "        filenames = os.listdir('../incremental/data/incremental/%s/s%d/%s/' % (str_freq , session_id , subjcet))\n",
    "        \n",
    "        person = np.concatenate([load_data('../incremental/data/incremental/%s/s%d/%s/%s' % (str_freq , session_id , subjcet , filename)) for filename in filenames] , axis = 0)\n",
    "        \n",
    "        person_data , person_label = separate( person , label = int(subjcet) , overlap_length = overlap_length)\n",
    "        \n",
    "        data.append(person_data)\n",
    "        labels.append(person_label)\n",
    "    \n",
    "    #合并数据\n",
    "    data = np.concatenate(data)\n",
    "    labels = np.concatenate(labels)\n",
    "    \n",
    "    #shuffle\n",
    "    idx_data = list(range(data.shape[0]))\n",
    "    np.random.shuffle(idx_data)\n",
    "\n",
    "    data = data[idx_data]\n",
    "    labels = labels[idx_data]\n",
    "    \n",
    "    return data , labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center(data , label):\n",
    "    centers = []\n",
    "    \n",
    "    for label_id in range(9): #一共9个受试者\n",
    "        equal_idx = np.where(label == label_id)\n",
    "    \n",
    "        center = np.mean(data[equal_idx] , axis = 0)\n",
    "        centers.append(center)\n",
    "        \n",
    "    return np.array(centers)\n",
    "\n",
    "def get_center_simple(data):\n",
    "    '''\n",
    "    计算单个用户的脑电的中心\n",
    "    '''\n",
    "    return np.mean(data , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense , Dropout , Conv2D , MaxPooling2D , Reshape , BatchNormalization , Flatten\n",
    "from keras.layers import Input , Deconv2D , UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape = (256*3 , 16 , 1))\n",
    "#encoder\n",
    "#VGG16结构\n",
    "encoder = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform')(encoder_input)\n",
    "encoder = Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform')(encoder)\n",
    "encoder = MaxPooling2D(pool_size=(2, 2))(encoder)\n",
    "encoder = Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform')(encoder)\n",
    "encoder = Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform')(encoder)\n",
    "encoder = MaxPooling2D(pool_size=(2, 2))(encoder)\n",
    "encoder = Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform')(encoder)\n",
    "encoder = Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform')(encoder)\n",
    "encoder = Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform')(encoder)\n",
    "encoder = MaxPooling2D(pool_size=(2, 2))(encoder)\n",
    "#new_add\n",
    "encoder_output = Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform')(encoder)\n",
    "encoder_output = MaxPooling2D(pool_size=(2, 2))(encoder_output)\n",
    "#shape = encoder_output.get_shape().as_list()\n",
    "\n",
    "encoder_output = Flatten()(encoder_output)\n",
    "encoder_output = Dense(128 , activation='relu')(encoder_output)\n",
    "encoder_output = Dense(64 , activation='relu')(encoder_output)\n",
    "\n",
    "#decoder\n",
    "decoder = Dense(128 , activation='relu')(encoder_output)\n",
    "decoder = Dense(48*1*32 , activation='relu')(decoder)\n",
    "decoder = Reshape(target_shape=(48,1,32))(decoder)\n",
    "decoder = UpSampling2D(size=(2,2))(decoder)\n",
    "decoder = Deconv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform')(decoder)\n",
    "decoder = UpSampling2D(size=(2,2))(decoder)\n",
    "decoder = Deconv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform')(decoder)\n",
    "decoder = Deconv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform')(decoder)\n",
    "decoder = Deconv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform')(decoder)\n",
    "decoder = UpSampling2D(size=(2,2))(decoder)\n",
    "decoder = Deconv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform')(decoder)\n",
    "decoder = Deconv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform')(decoder)\n",
    "decoder = UpSampling2D(size=(2,2))(decoder)\n",
    "decoder = Deconv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform')(decoder)\n",
    "decoder_output = Deconv2D(1, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform')(decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(inputs=encoder_input , outputs=decoder_output)\n",
    "encoder = Model(inputs=encoder_input , outputs=encoder_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA降维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kmeans聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq :  6\n",
      "session :  1 [[-0.09447385  0.02152621]\n",
      " [ 0.17780232  0.02640878]\n",
      " [-0.31032544  0.00113128]\n",
      " [ 0.09829488  0.00733593]\n",
      " [ 0.3119625   0.04017555]\n",
      " [ 0.23162887 -0.04797169]\n",
      " [-0.19264477  0.00541287]\n",
      " [-0.07017577 -0.0377712 ]\n",
      " [-0.01599316  0.00518708]] 0.0753941\n",
      "session :  3 [[-2.50459433e-01 -3.89048690e-03]\n",
      " [ 9.37072814e-01 -1.36329024e-03]\n",
      " [-1.38936758e-01  3.40981758e-03]\n",
      " [ 3.31222825e-02  8.69151577e-03]\n",
      " [-1.23882806e-02 -2.05367315e-03]\n",
      " [-9.23799872e-02 -9.16034542e-03]\n",
      " [-2.16429844e-01 -9.18807928e-04]\n",
      " [ 7.58526772e-02  1.04574477e-02]\n",
      " [-1.14069864e-01 -1.30800647e-03]] 0.052319400000000016\n",
      "session :  5 [[-0.29962343 -0.02279103]\n",
      " [ 1.4364731  -0.00462301]\n",
      " [-0.08738236  0.01413906]\n",
      " [-0.18177633  0.00171182]\n",
      " [-0.00922005  0.01715439]\n",
      " [-0.24331377 -0.00199639]\n",
      " [-0.1369013   0.00972961]\n",
      " [-0.20821495 -0.00338747]\n",
      " [-0.26914984 -0.01489906]] 0.05688499999999941\n",
      "session :  6 [[-0.14546417  0.00397042]\n",
      " [ 0.3117853  -0.04115033]\n",
      " [ 0.04934029  0.02871062]\n",
      " [-0.24601614 -0.01505077]\n",
      " [ 0.4616643  -0.00764577]\n",
      " [ 0.15073188  0.0478307 ]\n",
      " [-0.18841857 -0.00177327]\n",
      " [ 0.25959942 -0.04655226]\n",
      " [-0.1056082   0.00605628]] 0.056189400000000056\n",
      "session :  7 [[-0.28441098 -0.00425082]\n",
      " [ 1.8128167  -0.00623749]\n",
      " [ 0.04220897  0.04253119]\n",
      " [-0.1370095  -0.00634442]\n",
      " [-0.32947585 -0.00537658]\n",
      " [-0.23379998 -0.00378166]\n",
      " [-0.3096316  -0.00535637]\n",
      " [-0.2622719  -0.00665179]\n",
      " [-0.27414063 -0.00516961]] 0.052195899999999185\n",
      "session :  8 [[-0.12753673 -0.0153709 ]\n",
      " [ 0.62613845  0.02351069]\n",
      " [-0.3178109  -0.00493695]\n",
      " [ 0.90944403 -0.0806466 ]\n",
      " [ 0.3412607  -0.01341843]\n",
      " [ 0.51286227  0.00498147]\n",
      " [-0.21269347  0.02246875]\n",
      " [-0.03452419  0.03860785]\n",
      " [ 0.8897794   0.08130725]] 0.0734204000000016\n",
      "session :  9 [[-0.33024234 -0.0233114 ]\n",
      " [ 1.2540673  -0.0408792 ]\n",
      " [ 0.01306917  0.06046247]\n",
      " [-0.07771382  0.03764664]\n",
      " [ 0.19801901  0.09527919]\n",
      " [-0.20521426 -0.01127834]\n",
      " [-0.08207867 -0.0207046 ]\n",
      " [-0.2876836  -0.02127316]\n",
      " [ 0.14607507  0.08792953]] 0.05586730000000095\n",
      "session :  11 [[-0.3035738  -0.02770894]\n",
      " [ 1.3387562  -0.01513223]\n",
      " [ 0.10521135  0.03819298]\n",
      " [-0.15829909  0.00652653]\n",
      " [-0.21515986 -0.00850603]\n",
      " [-0.09965906  0.02628652]\n",
      " [-0.25546032 -0.01555383]\n",
      " [-0.03750723  0.05294806]\n",
      " [ 0.03952007  0.05038859]] 0.05709639999999894\n",
      "session :  12 [[-0.13832004 -0.00254092]\n",
      " [ 0.77389574 -0.02459105]\n",
      " [ 0.39247286  0.01340556]\n",
      " [-0.04612639  0.00247661]\n",
      " [ 1.0528212  -0.01730441]\n",
      " [-0.24557264 -0.01514104]\n",
      " [ 0.58112836 -0.00496714]\n",
      " [ 0.03402031  0.0151138 ]\n",
      " [ 0.14306326  0.03380636]] 0.0708675999999997\n",
      "session :  13 [[ 0.11584681  0.00928796]\n",
      " [-0.27462983 -0.00510534]\n",
      " [ 0.35688308 -0.01120668]\n",
      " [-0.066476    0.00829914]\n",
      " [ 0.00193572  0.01031282]\n",
      " [-0.14064437 -0.00930663]\n",
      " [-0.31351998 -0.00714543]\n",
      " [ 0.16411527  0.00683087]\n",
      " [ 0.496639   -0.00442009]] 0.0701552999999997\n",
      "freq :  7.5\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "cuDNN Backward Filter function launch failure : input shape([32,64,768,16]) filter shape([3,3,64,128])\n\t [[Node: training_1/Adam/gradients/conv2d_transpose_7/conv2d_transpose_grad/Conv2DBackpropFilter = Conv2DBackpropFilter[T=DT_FLOAT, _class=[\"loc:@training_1/Adam/gradients/conv2d_transpose_7/conv2d_transpose_grad/Conv2D\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_1/Adam/gradients/conv2d_transpose_7/Relu_grad/ReluGrad, training_1/Adam/gradients/conv2d_transpose_7/conv2d_transpose_grad/Shape, training_1/Adam/gradients/conv2d_transpose_7/conv2d_transpose_grad/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ee62f120ec63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#自编码器的训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_data\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmeta_data\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msession_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: cuDNN Backward Filter function launch failure : input shape([32,64,768,16]) filter shape([3,3,64,128])\n\t [[Node: training_1/Adam/gradients/conv2d_transpose_7/conv2d_transpose_grad/Conv2DBackpropFilter = Conv2DBackpropFilter[T=DT_FLOAT, _class=[\"loc:@training_1/Adam/gradients/conv2d_transpose_7/conv2d_transpose_grad/Conv2D\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_1/Adam/gradients/conv2d_transpose_7/Relu_grad/ReluGrad, training_1/Adam/gradients/conv2d_transpose_7/conv2d_transpose_grad/Shape, training_1/Adam/gradients/conv2d_transpose_7/conv2d_transpose_grad/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer)]]"
     ]
    }
   ],
   "source": [
    "for freq in [6]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    meta_data , meta_labels = combine(freq)\n",
    "    meta_data = np.expand_dims(meta_data , axis=-1)\n",
    "    meta_data = (meta_data-np.mean(meta_data)) / np.std(meta_data)\n",
    "    \n",
    "    #自编码器的训练\n",
    "    autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "    autoencoder.fit(meta_data , meta_data , batch_size=32 , epochs=50 , verbose=0)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.expand_dims(data , axis=-1)\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_pca = pca.fit_transform(data_feature)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=9)\n",
    "        start = time.clock()\n",
    "        _ = kmeans.fit_transform(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "                \n",
    "        print('session : ' , session_id , kmeans.cluster_centers_ , time1 + time2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq :  7.5\n",
      "session :  1 [[ 0.01434443  0.0054415 ]\n",
      " [-0.01400757  0.00109773]\n",
      " [ 0.05663577 -0.00079195]\n",
      " [-0.04609253 -0.00549186]\n",
      " [-0.02569692  0.00302371]\n",
      " [ 0.07353924 -0.00426977]\n",
      " [-0.05242095 -0.00332672]\n",
      " [ 0.04022407 -0.00111593]\n",
      " [-0.00041342  0.00190035]] 0.0722994\n",
      "session :  3 [[-0.00094921 -0.00457187]\n",
      " [ 0.07031219  0.00742467]\n",
      " [-0.02478894 -0.00170506]\n",
      " [ 0.01748855 -0.00453342]\n",
      " [-0.04395022  0.00873065]\n",
      " [-0.01362019  0.00231636]\n",
      " [ 0.02611357 -0.00470944]\n",
      " [ 0.00909596 -0.00490663]\n",
      " [-0.01045498 -0.00330922]] 0.06674129999999989\n",
      "session :  5 [[ 3.6440637e-02 -1.3496061e-03]\n",
      " [-2.3284905e-02  2.8257251e-03]\n",
      " [ 6.5395549e-02 -9.1374066e-04]\n",
      " [-5.0541103e-02 -2.5110247e-03]\n",
      " [-1.2639939e-03  2.1623841e-03]\n",
      " [ 5.1325273e-02  9.9537858e-05]\n",
      " [-3.1367294e-02 -8.0756581e-04]\n",
      " [ 7.8378811e-02 -2.4343953e-04]\n",
      " [-2.4218241e-02 -3.0707659e-03]] 0.06572109999999931\n",
      "session :  6 [[-7.9046851e-03  3.7753689e-05]\n",
      " [ 1.6243696e-01 -2.7789571e-04]\n",
      " [-2.9323896e-02  7.5860752e-04]\n",
      " [ 9.7628824e-02  4.7608554e-02]\n",
      " [-1.3229219e-02  1.8076919e-04]\n",
      " [ 4.3022562e-02  7.4836887e-02]\n",
      " [-1.5479586e-03 -2.5280780e-04]\n",
      " [-5.6991074e-03 -1.0385307e-03]\n",
      " [-3.5471544e-02  1.8349946e-03]] 0.05355470000000029\n",
      "session :  7 [[-3.3503976e-02  8.5965189e-04]\n",
      " [ 3.9283207e-01  4.2914043e-04]\n",
      " [ 5.8761269e-02 -4.7369357e-03]\n",
      " [-8.0315890e-03 -1.7088961e-03]\n",
      " [ 2.5685909e-01  8.9101948e-02]\n",
      " [ 1.4156795e-01  1.7998274e-01]\n",
      " [-2.6354833e-02  1.1482191e-04]\n",
      " [-3.6627416e-02  1.2865819e-03]\n",
      " [-2.1819107e-02 -4.1532214e-04]] 0.056180099999998845\n",
      "session :  8 [[-0.04100282 -0.00273467]\n",
      " [ 0.2084025  -0.00200857]\n",
      " [-0.00492735 -0.00159103]\n",
      " [-0.01537274  0.0155911 ]\n",
      " [-0.03417942 -0.00240639]\n",
      " [ 0.00599549  0.02697079]\n",
      " [-0.01482974 -0.00364792]\n",
      " [ 0.00280917 -0.00164092]\n",
      " [-0.00552801  0.02084541]] 0.06207389999999968\n",
      "session :  9 [[-0.00630138  0.00365981]\n",
      " [ 0.3079961  -0.00092984]\n",
      " [-0.04434958 -0.00047776]\n",
      " [-0.05598095 -0.00210896]\n",
      " [-0.05162283 -0.00147968]\n",
      " [-0.01299844  0.00328833]\n",
      " [-0.03336253  0.00097391]\n",
      " [ 0.00166878  0.00426896]\n",
      " [-0.0593904  -0.00254196]] 0.054061100000000195\n",
      "session :  11 [[ 0.03760021 -0.0129815 ]\n",
      " [-0.0337289  -0.00020934]\n",
      " [ 0.1434009   0.00367311]\n",
      " [ 0.00195384  0.00066156]\n",
      " [-0.00581493  0.01743418]\n",
      " [-0.01743526 -0.00139107]\n",
      " [-0.04155127 -0.00114484]\n",
      " [-0.020719    0.00983178]\n",
      " [-0.01385543  0.0132742 ]] 0.0563053\n",
      "session :  12 [[ 0.04213942  0.02333637]\n",
      " [-0.01221206  0.00037392]\n",
      " [ 0.07652827 -0.01608534]\n",
      " [-0.02487086 -0.00412575]\n",
      " [ 0.00599881  0.00937517]\n",
      " [ 0.10155844 -0.01900539]\n",
      " [ 0.02797063  0.01786217]\n",
      " [-0.03804674 -0.01127133]\n",
      " [ 0.05475082 -0.01479407]] 0.0579351999999993\n",
      "session :  13 [[-0.02187261 -0.00081502]\n",
      " [ 0.09551136  0.00035215]\n",
      " [ 0.01095751  0.00196371]\n",
      " [-0.00264087 -0.00189669]\n",
      " [ 0.11796831  0.0008823 ]\n",
      " [-0.02789298  0.00599488]\n",
      " [ 0.08116985 -0.00085977]\n",
      " [-0.01329651 -0.00178103]\n",
      " [ 0.02424923  0.00561663]] 0.0749139999999997\n"
     ]
    }
   ],
   "source": [
    "for freq in [7.5]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    meta_data , meta_labels = combine(freq)\n",
    "    meta_data = np.expand_dims(meta_data , axis=-1)\n",
    "    meta_data = (meta_data-np.mean(meta_data)) / np.std(meta_data)\n",
    "    \n",
    "    #自编码器的训练\n",
    "    autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "    autoencoder.fit(meta_data , meta_data , batch_size=32 , epochs=50 , verbose=0)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.expand_dims(data , axis=-1)\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_pca = pca.fit_transform(data_feature)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=9)\n",
    "        start = time.clock()\n",
    "        _ = kmeans.fit_transform(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "                \n",
    "        print('session : ' , session_id , kmeans.cluster_centers_ , time1 + time2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq :  8.5\n",
      "session :  1 [[-0.01969927 -0.00614698]\n",
      " [ 0.09092501 -0.00877074]\n",
      " [ 0.01948867  0.02933999]\n",
      " [-0.00899126  0.00263531]\n",
      " [-0.01665842 -0.00424609]\n",
      " [ 0.0136526   0.02408396]\n",
      " [-0.01615458 -0.00238109]\n",
      " [-0.0110978   0.00156123]\n",
      " [-0.00530589  0.00419104]] 0.0628644\n",
      "session :  3 [[ 0.01539399  0.02379128]\n",
      " [-0.01750782 -0.00271256]\n",
      " [ 0.08235874 -0.0091057 ]\n",
      " [-0.00445181 -0.00116051]\n",
      " [-0.01514146  0.00073359]\n",
      " [ 0.02187754  0.02796924]\n",
      " [-0.02132517 -0.00565634]\n",
      " [-0.00848832 -0.00197002]\n",
      " [-0.01788202 -0.00569959]] 0.05546169999999995\n",
      "session :  5 [[-0.01281557 -0.002678  ]\n",
      " [ 0.08550283 -0.00271057]\n",
      " [-0.00500562  0.00371323]\n",
      " [ 0.00270334  0.01175892]\n",
      " [-0.01110264  0.00199661]\n",
      " [-0.01688745 -0.00501842]\n",
      " [-0.01151746  0.00012789]\n",
      " [-0.00923877  0.00320081]\n",
      " [-0.01519627 -0.00381025]] 0.05574060000000003\n",
      "session :  6 [[-0.02241479 -0.00247682]\n",
      " [ 0.02571617 -0.00767023]\n",
      " [ 0.07060371 -0.00834391]\n",
      " [ 0.01694128  0.02998658]\n",
      " [-0.01545161  0.01452984]\n",
      " [-0.01952418 -0.00595921]\n",
      " [-0.02110474 -0.00876008]\n",
      " [ 0.03417512 -0.00783784]\n",
      " [ 0.07476242 -0.00915513]] 0.05531630000000032\n",
      "session :  7 [[-0.01640905 -0.00670743]\n",
      " [ 0.08710644 -0.00601797]\n",
      " [ 0.010509    0.02250703]\n",
      " [-0.0086004   0.00216161]\n",
      " [-0.01647371 -0.00208079]\n",
      " [-0.01327476 -0.00689627]\n",
      " [-0.01373195  0.00107809]\n",
      " [-0.009652   -0.00037574]\n",
      " [-0.01843727 -0.00511567]] 0.05247789999999952\n",
      "session :  8 [[-0.00918929  0.02458808]\n",
      " [-0.007462   -0.01861423]\n",
      " [ 0.0175313  -0.00064955]\n",
      " [-0.01488165  0.00018112]\n",
      " [ 0.01015179 -0.00326388]\n",
      " [-0.01273958 -0.00917696]\n",
      " [ 0.02242792  0.00232952]\n",
      " [ 0.00714177  0.00085284]\n",
      " [-0.01298011  0.00375299]] 0.05499709999999958\n",
      "session :  9 [[-0.01545885 -0.00774428]\n",
      " [ 0.08806791 -0.00943902]\n",
      " [ 0.01575153  0.01656124]\n",
      " [-0.01150252  0.0060735 ]\n",
      " [-0.0215951  -0.00563236]\n",
      " [ 0.00882806  0.01812284]\n",
      " [-0.01939588 -0.00328754]\n",
      " [ 0.01044841  0.01225989]\n",
      " [-0.02093676 -0.007057  ]] 0.05462890000000087\n",
      "session :  11 [[-0.01005976 -0.00274769]\n",
      " [ 0.02074751 -0.01365377]\n",
      " [ 0.02933614  0.02557252]\n",
      " [-0.01227169  0.00357736]\n",
      " [ 0.01665553 -0.0180203 ]\n",
      " [ 0.02575252 -0.015717  ]\n",
      " [-0.01153456  0.00154238]\n",
      " [-0.01184675  0.00027215]\n",
      " [ 0.0293299  -0.01703892]] 0.05609880000000089\n",
      "session :  12 [[-0.01923092 -0.00297065]\n",
      " [ 0.08398775 -0.00964524]\n",
      " [ 0.01708384  0.02440184]\n",
      " [-0.00684157 -0.00073429]\n",
      " [-0.01239569 -0.00130261]\n",
      " [ 0.02372486  0.02870787]\n",
      " [-0.01526168 -0.00090965]\n",
      " [-0.02033619 -0.00442003]\n",
      " [-0.00979245 -0.00175845]] 0.05444060000000306\n",
      "session :  13 [[-0.02212041 -0.00080965]\n",
      " [ 0.07456099 -0.00586978]\n",
      " [ 0.00950972  0.02360167]\n",
      " [-0.01009261 -0.00754557]\n",
      " [-0.00456279  0.00850749]\n",
      " [-0.01747332  0.00494906]\n",
      " [ 0.09006397 -0.00462568]\n",
      " [-0.0089574  -0.01439828]\n",
      " [-0.01563195 -0.00377575]] 0.05840520000000282\n"
     ]
    }
   ],
   "source": [
    "for freq in [8.5]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    meta_data , meta_labels = combine(freq)\n",
    "    meta_data = np.expand_dims(meta_data , axis=-1)\n",
    "    meta_data = (meta_data-np.mean(meta_data)) / np.std(meta_data)\n",
    "    \n",
    "    #自编码器的训练\n",
    "    autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "    autoencoder.fit(meta_data , meta_data , batch_size=32 , epochs=50 , verbose=0)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.expand_dims(data , axis=-1)\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_pca = pca.fit_transform(data_feature)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=9)\n",
    "        start = time.clock()\n",
    "        _ = kmeans.fit_transform(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "                \n",
    "        print('session : ' , session_id , kmeans.cluster_centers_ , time1 + time2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq :  10\n",
      "session :  1 [[-3.5306129e-03 -6.4287230e-04]\n",
      " [ 1.8940449e-02 -7.2372693e-04]\n",
      " [ 3.8420421e-03  1.7443667e-03]\n",
      " [-3.9269132e-04  5.6607096e-04]\n",
      " [-2.2643523e-03  5.8840972e-04]\n",
      " [-4.1958014e-03 -5.0490384e-04]\n",
      " [ 8.2645757e-04  2.6698883e-03]\n",
      " [-3.2479565e-03 -3.1466356e-05]\n",
      " [-4.7385069e-03 -5.9664028e-04]] 0.0599142\n",
      "session :  3 [[-7.3933206e-03 -4.8460756e-04]\n",
      " [ 3.8379781e-02 -1.2296221e-03]\n",
      " [ 6.2044505e-03  3.0324527e-03]\n",
      " [-5.6392956e-04  1.0254397e-03]\n",
      " [ 3.5400398e-02  1.0468729e-05]\n",
      " [ 4.0754292e-02 -2.2830728e-03]\n",
      " [ 7.1406690e-03  3.2751812e-03]\n",
      " [ 1.1552724e-03  1.3596849e-03]\n",
      " [-7.8349365e-03 -6.3385128e-04]] 0.052649600000000074\n",
      "session :  5 [[-2.6629707e-03 -1.3150883e-04]\n",
      " [ 3.2910853e-04  1.6367510e-05]\n",
      " [ 6.9533591e-03 -4.6195151e-04]\n",
      " [ 2.3899609e-03  5.8901962e-04]\n",
      " [-1.7301593e-03  2.6212740e-05]\n",
      " [ 1.6405578e-03  2.7575187e-04]\n",
      " [-2.3593791e-03 -2.4875448e-04]\n",
      " [ 1.1516995e-03 -3.7068698e-05]\n",
      " [-2.5512588e-03  2.8122964e-05]] 0.05377960000000037\n",
      "session :  6 [[-5.2292598e-03  4.0189404e-04]\n",
      " [ 2.4197120e-02 -1.4807553e-04]\n",
      " [ 4.8565431e-03 -2.3210309e-03]\n",
      " [-1.8628731e-03 -2.7949069e-04]\n",
      " [ 3.0292897e-02  3.3717449e-03]\n",
      " [ 7.4010817e-03 -2.9357823e-03]\n",
      " [-3.2712342e-03 -7.8976242e-05]\n",
      " [ 3.1439050e-03 -1.8030902e-03]\n",
      " [ 2.5421735e-02  5.8610801e-04]] 0.05757499999999993\n",
      "session :  7 [[ 2.8086284e-03  2.8286537e-04]\n",
      " [-1.5731052e-03 -3.2326388e-05]\n",
      " [ 7.4197678e-03 -1.4242424e-04]\n",
      " [ 4.6664488e-04 -4.2075093e-04]\n",
      " [-2.0470831e-03 -5.6809353e-05]\n",
      " [-3.2792171e-04  3.9799893e-04]\n",
      " [-9.4835821e-04  1.1013919e-03]\n",
      " [ 3.1166414e-03  3.5195140e-04]\n",
      " [-2.2627644e-03 -8.4780862e-05]] 0.053131300000000437\n",
      "session :  8 [[ 1.6748086e-02 -5.2873592e-04]\n",
      " [-1.7174266e-03 -3.4266766e-05]\n",
      " [ 5.0699855e-03  7.3699676e-04]\n",
      " [-4.0102932e-03 -9.6781376e-05]\n",
      " [ 1.3834724e-02 -2.0476971e-04]\n",
      " [-8.5817470e-04  2.7902677e-05]\n",
      " [-2.5443844e-03 -7.0495291e-05]\n",
      " [ 1.2599777e-02 -1.4882714e-04]\n",
      " [ 1.4836159e-02 -3.1055039e-04]] 0.053506100000001666\n",
      "session :  9 [[-9.35546821e-04 -5.41917339e-04]\n",
      " [ 1.27481986e-02 -1.56477952e-04]\n",
      " [ 6.05202932e-03  8.36529478e-04]\n",
      " [-2.96956650e-03 -2.96070357e-06]\n",
      " [ 9.28889681e-03 -9.56756994e-05]\n",
      " [ 1.46336155e-02 -8.71106051e-04]\n",
      " [-1.88944081e-03  3.11904354e-04]\n",
      " [-3.28323944e-03 -6.76636482e-05]\n",
      " [ 1.13560054e-02 -1.78236551e-05]] 0.05088759999999937\n",
      "session :  11 [[-0.0035577   0.00030024]\n",
      " [ 0.01906078 -0.00037584]\n",
      " [ 0.00084164  0.00100626]\n",
      " [-0.00225953 -0.00081311]\n",
      " [-0.00555064 -0.00054551]\n",
      " [ 0.02097636 -0.00075297]\n",
      " [-0.00087772  0.00051529]\n",
      " [-0.0040979  -0.00036429]\n",
      " [ 0.01661032  0.0002643 ]] 0.060484000000002425\n",
      "session :  12 [[ 5.1511424e-03 -4.5375168e-04]\n",
      " [-2.5090990e-03 -1.8300260e-04]\n",
      " [-6.0922754e-05  3.4123205e-04]\n",
      " [ 3.5650642e-03  2.8211024e-04]\n",
      " [-3.0628885e-03  5.5654709e-05]\n",
      " [ 7.6234969e-04  1.6721473e-04]\n",
      " [ 6.7791510e-03 -2.3355937e-04]\n",
      " [-1.5391223e-03  2.1172089e-04]\n",
      " [-3.7971691e-03 -1.6882062e-04]] 0.06926409999999805\n",
      "session :  13 [[-0.0051471  -0.00043048]\n",
      " [ 0.01860765 -0.00117023]\n",
      " [ 0.00639369  0.00147795]\n",
      " [ 0.00153456  0.00158974]\n",
      " [ 0.01052978  0.00091928]\n",
      " [-0.00177359  0.00023941]\n",
      " [-0.00590804 -0.00033319]\n",
      " [-0.00428654 -0.00036933]\n",
      " [ 0.00906733  0.00122134]] 0.05443299999999596\n"
     ]
    }
   ],
   "source": [
    "for freq in [10]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    meta_data , meta_labels = combine(freq)\n",
    "    meta_data = np.expand_dims(meta_data , axis=-1)\n",
    "    meta_data = (meta_data-np.mean(meta_data)) / np.std(meta_data)\n",
    "    \n",
    "    #自编码器的训练\n",
    "    autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "    autoencoder.fit(meta_data , meta_data , batch_size=32 , epochs=50 , verbose=0)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.expand_dims(data , axis=-1)\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_pca = pca.fit_transform(data_feature)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=9)\n",
    "        start = time.clock()\n",
    "        _ = kmeans.fit_transform(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "                \n",
    "        print('session : ' , session_id , kmeans.cluster_centers_ , time1 + time2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq :  6\n",
      "session :  1 [[-0.00757415  0.00119063]\n",
      " [ 0.03676995 -0.00802503]\n",
      " [ 0.01329238  0.00966795]\n",
      " [-0.01064601 -0.00112506]\n",
      " [-0.01651772 -0.00355853]\n",
      " [-0.00544219 -0.00469479]\n",
      " [ 0.00576645  0.00857607]\n",
      " [-0.00307717  0.00639659]\n",
      " [ 0.00080191 -0.00081612]] 0.0324387\n",
      "session :  3 [[           nan            nan]\n",
      " [ 9.4452828e-02  7.6971373e-05]\n",
      " [-1.1806602e-02 -9.6239910e-06]\n",
      " [           nan            nan]\n",
      " [           nan            nan]\n",
      " [           nan            nan]\n",
      " [           nan            nan]\n",
      " [           nan            nan]\n",
      " [           nan            nan]] 0.03578440000000027\n",
      "session :  5 [[        nan         nan]\n",
      " [ 0.1563898  -0.00109791]\n",
      " [-0.02786399 -0.00393227]\n",
      " [ 0.00025336  0.00585341]\n",
      " [-0.02421495 -0.00200753]\n",
      " [-0.01284182  0.00470128]\n",
      " [-0.01878054 -0.00112652]\n",
      " [-0.00496752  0.00649125]\n",
      " [-0.01629715  0.00075972]] 0.04120349999999995\n",
      "session :  6 [[-0.03168932  0.00158185]\n",
      " [ 0.09043541  0.02288529]\n",
      " [ 0.01700126 -0.01470964]\n",
      " [ 0.08108009 -0.02099777]\n",
      " [ 0.09577143  0.02334429]\n",
      " [-0.02543893  0.00088833]\n",
      " [-0.03551694  0.00258169]\n",
      " [ 0.08295257 -0.01870482]\n",
      " [ 0.07516161 -0.01756458]] 0.02459220000000073\n",
      "session :  7 [[        nan         nan]\n",
      " [ 0.01886672  0.00961758]\n",
      " [ 0.02628489 -0.00687068]\n",
      " [ 0.00503287 -0.00136747]\n",
      " [-0.00412325 -0.00082613]\n",
      " [-0.00798655 -0.00027447]\n",
      " [-0.01141974  0.00018133]\n",
      " [-0.00656116 -0.0002777 ]\n",
      " [        nan         nan]] 0.035348300000000776\n",
      "session :  8 [[-0.00108638  0.00181609]\n",
      " [ 0.06094678 -0.00510864]\n",
      " [-0.0223638  -0.0088519 ]\n",
      " [ 0.00910648  0.01426434]\n",
      " [ 0.09347303 -0.00673169]\n",
      " [-0.01354153  0.00438574]\n",
      " [-0.00613003 -0.00405841]\n",
      " [ 0.04578032 -0.00134923]\n",
      " [-0.01874174 -0.00475832]] 0.024231499999999073\n",
      "session :  9 [[-0.02832513 -0.00289352]\n",
      " [ 0.11812832 -0.02216559]\n",
      " [ 0.0520139   0.04025316]\n",
      " [-0.00936768 -0.00251478]\n",
      " [ 0.00566379  0.00150954]\n",
      " [-0.03250929 -0.00320785]\n",
      " [-0.01144333 -0.00056389]\n",
      " [-0.01477379 -0.00073437]\n",
      " [-0.0037812   0.00047401]] 0.0280832999999987\n",
      "session :  11 [[ 0.14690916 -0.00383064]\n",
      " [-0.02015954 -0.00087931]\n",
      " [ 0.00406566  0.01163514]\n",
      " [-0.02659975 -0.00431088]\n",
      " [-0.00264971  0.00747399]\n",
      " [-0.01323114  0.00215194]\n",
      " [-0.00694841  0.00529713]\n",
      " [ 0.00515603  0.01709403]\n",
      " [-0.02160165 -0.0022221 ]] 0.021119500000001068\n",
      "session :  12 [[-0.01841527 -0.00216505]\n",
      " [ 0.06763165 -0.00493467]\n",
      " [ 0.01126     0.00863306]\n",
      " [ 0.10428724 -0.00632444]\n",
      " [ 0.00244193  0.00654729]\n",
      " [ 0.04954273 -0.00076799]\n",
      " [-0.02308343 -0.00798141]\n",
      " [-0.00471162  0.00870199]\n",
      " [-0.00638872 -0.00131739]] 0.01786639999999906\n",
      "session :  13 [[-0.01307676  0.00135297]\n",
      " [ 0.04574737 -0.00489706]\n",
      " [ 0.0036163  -0.00206033]\n",
      " [ 0.00109934  0.00953245]\n",
      " [-0.02188944 -0.0039256 ]\n",
      " [ 0.00729864  0.00802819]\n",
      " [-0.00240907 -0.0031958 ]\n",
      " [-0.01393492 -0.00409415]\n",
      " [-0.00807821 -0.00127717]] 0.018795799999999474\n"
     ]
    }
   ],
   "source": [
    "for freq in [6]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    meta_data , meta_labels = combine(freq)\n",
    "    meta_data = np.expand_dims(meta_data , axis=-1)\n",
    "    meta_data = (meta_data-np.mean(meta_data)) / np.std(meta_data)\n",
    "    \n",
    "    #自编码器的训练\n",
    "    autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "    autoencoder.fit(meta_data , meta_data , batch_size=32 , epochs=50 , verbose=0)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.expand_dims(data , axis=-1)\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_pca = pca.fit_transform(data_feature)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        gmm = GaussianMixture(n_components=9)\n",
    "        start = time.clock()\n",
    "        res = gmm.fit_predict(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        _centers = get_center(X_pca , res)\n",
    "        \n",
    "        print('session : ' , session_id , _centers , time1 + time2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq :  7.5\n",
      "session :  1 [[ 9.4154358e+00 -6.4416417e-06]\n",
      " [-3.3637600e+00  7.8739570e-03]\n",
      " [ 2.3773577e+00  4.3822862e-02]\n",
      " [-7.2009974e+00 -5.4437004e-02]\n",
      " [ 8.7993031e+00 -9.1961935e-02]\n",
      " [-1.5915577e+00  3.1003214e-02]\n",
      " [ 4.6752100e+00  4.6495315e-02]\n",
      " [-2.4704182e+00  6.5240353e-02]\n",
      " [-8.5239449e+00 -1.2966301e-02]] 0.0678126\n",
      "session :  3 [[-3.7276573e+00  1.2103634e-02]\n",
      " [ 5.6900883e+00  2.0343222e-02]\n",
      " [ 2.3716626e+00  1.6483216e-01]\n",
      " [-7.0868492e+00 -9.7047232e-02]\n",
      " [-2.3997145e+00  4.9333512e-03]\n",
      " [ 8.3823442e+00 -1.0304502e-01]\n",
      " [ 3.3365636e+00  2.3169173e-02]\n",
      " [-7.3241287e-01  7.5617820e-02]\n",
      " [ 4.8878803e+00 -1.1093919e-03]] 0.03427680000000022\n",
      "session :  5 [[-1.2619125e+00  1.9357963e-02]\n",
      " [ 1.1858756e+01 -1.7231476e-02]\n",
      " [-6.6963682e+00  1.5455200e-02]\n",
      " [ 1.2719468e+01  8.5513785e-02]\n",
      " [-4.6376929e+00 -4.1973196e-02]\n",
      " [ 5.7854503e-01 -6.2906273e-02]\n",
      " [ 1.3995359e+01  2.8194884e-02]\n",
      " [-7.4599881e+00  5.5054501e-02]\n",
      " [-3.4662671e+00  9.7579183e-03]] 0.04269630000000024\n",
      "session :  6 [[-1.0117387e+00 -6.8340781e-03]\n",
      " [ 1.4876234e+01 -2.9249545e-02]\n",
      " [-4.6140099e+00 -6.2594325e-03]\n",
      " [ 1.2010940e-02  5.8388691e-03]\n",
      " [ 3.8596272e-01  1.0860414e-04]\n",
      " [ 8.7981186e+00  2.6849592e+00]\n",
      " [ 1.0720999e+00  2.2597070e+00]\n",
      " [-5.5641623e+00 -8.6949430e-03]\n",
      " [-1.4583088e+00 -4.7462308e-03]] 0.05559379999999958\n",
      "session :  7 [[-5.74400997e+00 -6.67123264e-03]\n",
      " [ 7.08914642e+01 -1.91076860e-01]\n",
      " [ 1.46813545e+01  3.64875682e-02]\n",
      " [-3.66111445e+00 -2.28419155e-02]\n",
      " [ 4.79465675e+01  9.57339859e+00]\n",
      " [-6.45078659e+00 -4.40521911e-03]\n",
      " [ 1.95231895e+01  7.27561426e+00]\n",
      " [-5.25557899e+00 -3.86094837e-03]\n",
      " [-4.71391439e+00 -3.28256562e-02]] 0.03333750000000002\n",
      "session :  8 [[-6.9613538e+00 -2.5971135e-02]\n",
      " [ 4.7903629e+01 -1.8344987e-02]\n",
      " [-2.0654361e+00 -5.5809761e-03]\n",
      " [-8.6680937e+00 -4.9062118e-02]\n",
      " [-1.2221230e+00  3.2251917e-02]\n",
      " [-4.1358032e+00  1.6383661e-01]\n",
      " [ 5.7317108e-02  3.5957124e-02]\n",
      " [-9.2113714e+00 -4.3790087e-02]\n",
      " [-4.1159844e+00  1.8247977e-01]] 0.044654599999999434\n",
      "session :  9 [[-9.5909204e+00 -2.0485299e-02]\n",
      " [ 6.4822678e+01 -1.1200957e-02]\n",
      " [-9.4544160e-01  5.7453655e-02]\n",
      " [-7.1323423e+00  5.0093312e-02]\n",
      " [-1.1006839e+01 -2.3137765e-02]\n",
      " [-8.6423588e+00 -1.0945556e-02]\n",
      " [-5.7417421e+00  1.2421766e-02]\n",
      " [-1.0154976e+00  1.0323545e-01]\n",
      " [-1.1652494e+01 -4.6521481e-02]] 0.029496499999998704\n",
      "session :  11 [[-6.4983048e+00 -3.1086052e-02]\n",
      " [ 3.3409603e+01 -1.0849113e-01]\n",
      " [ 9.4456244e+00  2.8867179e-01]\n",
      " [-4.2463651e+00 -4.0329561e-02]\n",
      " [-9.1927557e+00  7.5973072e-03]\n",
      " [-8.1658821e+00  4.8429541e-05]\n",
      " [-2.8021650e+00 -1.7565887e-02]\n",
      " [-4.6560040e+00 -6.4313181e-02]\n",
      " [-7.2967119e+00 -3.4707721e-02]] 0.0315171000000003\n",
      "session :  12 [[ 8.5852871e+00 -1.4286613e-02]\n",
      " [-1.8073370e+00 -7.2429259e-03]\n",
      " [-4.8026052e+00 -2.9193845e-02]\n",
      " [ 2.7912354e+00  6.8598494e-02]\n",
      " [ 5.9304848e+00 -5.5790175e-02]\n",
      " [ 1.0581102e+01 -7.4022286e-02]\n",
      " [-5.6824884e+00 -2.4201436e-02]\n",
      " [-7.4411672e-01  4.4236984e-02]\n",
      " [ 7.3429923e+00 -2.1267544e-02]] 0.028586100000001835\n",
      "session :  13 [[-1.2260845e+00 -1.4643081e-02]\n",
      " [ 1.5837868e+01 -1.3265019e-02]\n",
      " [-4.3597422e+00  1.2938693e-02]\n",
      " [ 2.4973319e+00  2.1244695e-02]\n",
      " [ 2.1755871e+01  1.0071163e+00]\n",
      " [-2.6133087e+00 -1.4957033e-02]\n",
      " [ 1.8104967e+01  1.1240275e-01]\n",
      " [-4.0214911e-01  6.0002323e-02]\n",
      " [ 1.9586893e+01 -3.0840347e-02]] 0.042093600000001175\n"
     ]
    }
   ],
   "source": [
    "for freq in [7.5]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    meta_data , meta_labels = combine(freq)\n",
    "    meta_data = np.expand_dims(meta_data , axis=-1)\n",
    "    meta_data = (meta_data-np.mean(meta_data)) / np.std(meta_data)\n",
    "    \n",
    "    #自编码器的训练\n",
    "    autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "    autoencoder.fit(meta_data , meta_data , batch_size=32 , epochs=50 , verbose=0)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.expand_dims(data , axis=-1)\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_pca = pca.fit_transform(data_feature)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        gmm = GaussianMixture(n_components=9)\n",
    "        start = time.clock()\n",
    "        res = gmm.fit_predict(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        _centers = get_center(X_pca , res)\n",
    "        \n",
    "        print('session : ' , session_id , _centers , time1 + time2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq :  8.5\n"
     ]
    }
   ],
   "source": [
    "for freq in [8.5]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    meta_data , meta_labels = combine(freq)\n",
    "    meta_data = np.expand_dims(meta_data , axis=-1)\n",
    "    meta_data = (meta_data-np.mean(meta_data)) / np.std(meta_data)\n",
    "    \n",
    "    #自编码器的训练\n",
    "    autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "    autoencoder.fit(meta_data , meta_data , batch_size=32 , epochs=50 , verbose=0)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.expand_dims(data , axis=-1)\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_pca = pca.fit_transform(data_feature)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        gmm = GaussianMixture(n_components=9)\n",
    "        start = time.clock()\n",
    "        res = gmm.fit_predict(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        _centers = get_center(X_pca , res)\n",
    "        \n",
    "        print('session : ' , session_id , _centers , time1 + time2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for freq in [10]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    meta_data , meta_labels = combine(freq)\n",
    "    meta_data = np.expand_dims(meta_data , axis=-1)\n",
    "    meta_data = (meta_data-np.mean(meta_data)) / np.std(meta_data)\n",
    "    \n",
    "    #自编码器的训练\n",
    "    autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "    autoencoder.fit(meta_data , meta_data , batch_size=32 , epochs=50 , verbose=0)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.expand_dims(data , axis=-1)\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_pca = pca.fit_transform(data_feature)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        gmm = GaussianMixture(n_components=9)\n",
    "        start = time.clock()\n",
    "        res = gmm.fit_predict(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        _centers = get_center(X_pca , res)\n",
    "        \n",
    "        print('session : ' , session_id , _centers , time1 + time2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA降维\n",
    "## kmeans聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

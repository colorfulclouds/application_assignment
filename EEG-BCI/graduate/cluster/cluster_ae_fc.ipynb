{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "import seaborn as sns #绘制confusion matrix heatmap\n",
    "\n",
    "import os\n",
    "import scipy.io as sio\n",
    "\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import tqdm\n",
    "import  time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras.backend.tensorflow_backend as KTF\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore') #忽略警告\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 256\n",
    "origin_channel = 16\n",
    "\n",
    "\n",
    "SAMPLE_CHANNEL = ['Pz' , 'PO3' , 'PO4' , 'O1' , 'O2' , 'Oz' , 'O9' , 'FP2' ,\n",
    "                  'C4' , 'C6' , 'CP3' , 'CP1' ,\n",
    "                  'CPZ' , 'CP2' , 'CP4' , 'PO8']\n",
    "\n",
    "LABEL2STR = {0:'sen' , 1:'hong' , 2:'zhao',\n",
    "             3:'fen' , 4:'xiao' , 5:'yu' , \n",
    "             6:'bin' , 7:'wang' , 8:'wei' , \n",
    "             9:'fei'}\n",
    "\n",
    "CLIP_FORWARD = 1 #首部裁掉时间\n",
    "CLIP_BACKWARD = 1 #尾部裁掉时间\n",
    "\n",
    "trial_time = 3 #segment second\n",
    "\n",
    "\n",
    "#是否进行归一化\n",
    "#reference:a study on performance increasing in ssvep based bci application\n",
    "#IS_NORMALIZE = True\n",
    "\n",
    "#是否进行滤波\n",
    "#IS_FILTER = False\n",
    "#EEG频率范围\n",
    "#reference:a study on performance increasing in ssvep based bci application\n",
    "LO_FREQ = 0.5\n",
    "HI_FREQ = 40\n",
    "\n",
    "#是否陷波\n",
    "#IS_NOTCH = False\n",
    "NOTCH_FREQ = 50 #陷波 工频\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "\n",
    "    data = sio.loadmat(file_name=filename)['data_received'] #length*16 matrix\n",
    "\n",
    "    data = data[CLIP_FORWARD * sample_rate : - CLIP_BACKWARD * sample_rate] #首部 尾部 进行裁剪\n",
    "   \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(data , label , overlap_length):\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "\n",
    "    size = sample_rate * trial_time #一小段 256*3 个数据点\n",
    "    data_length = data.shape[0]\n",
    "\n",
    "    idx = 0\n",
    "    \n",
    "    while idx<=data_length-size:\n",
    "        train_data.append(data[idx : idx+size , :])\n",
    "        train_labels.append(label)\n",
    "\n",
    "        idx = idx + (size - overlap_length)\n",
    "        \n",
    "    return np.array(train_data) , np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_t_v(filenames):\n",
    "    # np.random.shuffle(filenames)\n",
    "    \n",
    "    return np.random.choice(filenames , size=10) #20次的计算准确率中 每次随机选择10个样本进行训练测试\n",
    "\n",
    "def combine(freq):    \n",
    "    overlap_length = 2*256 #重叠2秒数据\n",
    "    \n",
    "    #保证随机性 进行置乱\n",
    "    person_0_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/0/' % freq) )\n",
    "    person_1_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/1/' % freq) )\n",
    "    person_2_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/2/' % freq) )\n",
    "    person_3_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/3/' % freq) )\n",
    "    person_4_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/4/' % freq) )\n",
    "    person_5_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/5/' % freq) )\n",
    "    person_6_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/6/' % freq) )\n",
    "    person_7_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/7/' % freq) )\n",
    "    person_8_filenames = shuffle_t_v( os.listdir('../incremental/data/base_rf/%s/8/' % freq) )\n",
    "\n",
    "    #打开信号文件 并 合并\n",
    "    person_0 = np.concatenate([load_data('../incremental/data/base_rf/%s/0/' % freq + filename) for filename in person_0_filenames] , axis = 0)\n",
    "    person_1 = np.concatenate([load_data('../incremental/data/base_rf/%s/1/' % freq + filename) for filename in person_1_filenames] , axis = 0)\n",
    "    person_2 = np.concatenate([load_data('../incremental/data/base_rf/%s/2/' % freq + filename) for filename in person_2_filenames] , axis = 0)\n",
    "    person_3 = np.concatenate([load_data('../incremental/data/base_rf/%s/3/' % freq + filename) for filename in person_3_filenames] , axis = 0)\n",
    "    person_4 = np.concatenate([load_data('../incremental/data/base_rf/%s/4/' % freq + filename) for filename in person_4_filenames] , axis = 0)\n",
    "    person_5 = np.concatenate([load_data('../incremental/data/base_rf/%s/5/' % freq + filename) for filename in person_5_filenames] , axis = 0)\n",
    "    person_6 = np.concatenate([load_data('../incremental/data/base_rf/%s/6/' % freq + filename) for filename in person_6_filenames] , axis = 0)\n",
    "    person_7 = np.concatenate([load_data('../incremental/data/base_rf/%s/7/' % freq + filename) for filename in person_7_filenames] , axis = 0)\n",
    "    person_8 = np.concatenate([load_data('../incremental/data/base_rf/%s/8/' % freq + filename) for filename in person_8_filenames] , axis = 0)\n",
    "    \n",
    "    #============\n",
    "    #训练数据分段\n",
    "    train_person_data_0 , train_person_labels_0 = separate(person_0 , label = 0 , overlap_length=overlap_length)\n",
    "    train_person_data_1 , train_person_labels_1 = separate(person_1 , label = 1 , overlap_length=overlap_length)\n",
    "    train_person_data_2 , train_person_labels_2 = separate(person_2 , label = 2 , overlap_length=overlap_length)\n",
    "    train_person_data_3 , train_person_labels_3 = separate(person_3 , label = 3 , overlap_length=overlap_length)\n",
    "    train_person_data_4 , train_person_labels_4 = separate(person_4 , label = 4 , overlap_length=overlap_length)\n",
    "    train_person_data_5 , train_person_labels_5 = separate(person_5 , label = 5 , overlap_length=overlap_length)\n",
    "    train_person_data_6 , train_person_labels_6 = separate(person_6 , label = 6 , overlap_length=overlap_length)\n",
    "    train_person_data_7 , train_person_labels_7 = separate(person_7 , label = 7 , overlap_length=overlap_length)\n",
    "    train_person_data_8 , train_person_labels_8 = separate(person_8 , label = 8 , overlap_length=overlap_length)\n",
    "\n",
    "    #合并数据\n",
    "    train_data = np.concatenate((train_person_data_0 , train_person_data_1 , train_person_data_2 ,\n",
    "                                 train_person_data_3 , train_person_data_4 , train_person_data_5 ,\n",
    "                                 train_person_data_6 , train_person_data_7 , train_person_data_8 ,\n",
    "                                 ))\n",
    "    \n",
    "    train_labels = np.concatenate((train_person_labels_0 , train_person_labels_1 , train_person_labels_2 ,\n",
    "                                   train_person_labels_3 , train_person_labels_4 , train_person_labels_5 ,\n",
    "                                   train_person_labels_6 , train_person_labels_7 , train_person_labels_8 ,\n",
    "                                    ))\n",
    "    \n",
    "    #产生索引并置乱\n",
    "    idx_train_data = list(range(train_data.shape[0]))\n",
    "    np.random.shuffle(idx_train_data)\n",
    "\n",
    "    #将训练数据置乱\n",
    "    train_data = train_data[idx_train_data]\n",
    "    train_labels = train_labels[idx_train_data]\n",
    "        \n",
    "    return train_data , train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_data_labels(session_id , freq , is_training):\n",
    "    if is_training:\n",
    "        overlap_length = 256*2\n",
    "    else:\n",
    "        overlap_length = 0\n",
    "    \n",
    "    str_freq = str(freq)\n",
    "    \n",
    "    subjcets = os.listdir('../incremental/data/incremental/%s/s%d/' % (str_freq , session_id)) #受试者ID\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for subjcet in subjcets:\n",
    "        filenames = os.listdir('../incremental/data/incremental/%s/s%d/%s/' % (str_freq , session_id , subjcet))\n",
    "        \n",
    "        person = np.concatenate([load_data('../incremental/data/incremental/%s/s%d/%s/%s' % (str_freq , session_id , subjcet , filename)) for filename in filenames] , axis = 0)\n",
    "        \n",
    "        person_data , person_label = separate( person , label = int(subjcet) , overlap_length = overlap_length)\n",
    "        \n",
    "        data.append(person_data)\n",
    "        labels.append(person_label)\n",
    "    \n",
    "    #合并数据\n",
    "    data = np.concatenate(data)\n",
    "    labels = np.concatenate(labels)\n",
    "    \n",
    "    #shuffle\n",
    "    idx_data = list(range(data.shape[0]))\n",
    "    np.random.shuffle(idx_data)\n",
    "\n",
    "    data = data[idx_data]\n",
    "    labels = labels[idx_data]\n",
    "    \n",
    "    return data , labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center(data , label):\n",
    "    centers = []\n",
    "    \n",
    "    for label_id in range(9): #一共9个受试者\n",
    "        equal_idx = np.where(label == label_id)\n",
    "    \n",
    "        center = np.mean(data[equal_idx] , axis = 0)\n",
    "        centers.append(center)\n",
    "        \n",
    "    return np.array(centers)\n",
    "\n",
    "def get_center_simple(data):\n",
    "    '''\n",
    "    计算单个用户的脑电的中心\n",
    "    '''\n",
    "    return np.mean(data , axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA降维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kmeans聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense , Dropout , Conv2D , MaxPooling2D , Reshape , BatchNormalization , Flatten\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape = (256*3*16 , ))\n",
    "\n",
    "#encoder\n",
    "encoder = Dense(units=512 , activation='relu')(encoder_input)\n",
    "encoder = Dense(units=256 , activation='relu')(encoder)\n",
    "encoder = Dense(units=128 , activation='relu')(encoder)\n",
    "encoder_output = Dense(units=64 , activation='relu')(encoder) #聚类需要使用的2维特征\n",
    "\n",
    "#decoder\n",
    "decoder = Dense(units=128 , activation='relu')(encoder_output)\n",
    "decoder = Dense(units=256 , activation='relu')(decoder)\n",
    "decoder = Dense(units=512 , activation='relu')(decoder)\n",
    "decoder_output = Dense(units=256*3*16 , activation='relu')(decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(inputs=encoder_input , outputs=decoder_output)\n",
    "encoder = Model(inputs=encoder_input , outputs=encoder_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq :  6\n",
      "session :  1 [[ 841.03406     15.79293  ]\n",
      " [-226.33699    -29.086267 ]\n",
      " [ 389.8304     -15.756354 ]\n",
      " [-164.90143    176.24994  ]\n",
      " [ 263.31952    -24.09588  ]\n",
      " [ 622.456        2.302034 ]\n",
      " [ 115.28172    -26.212023 ]\n",
      " [ -60.116352   -44.424652 ]\n",
      " [ 514.0633      -1.5250419]] 0.1972731\n",
      "session :  3 [[-213.88426    88.404755]\n",
      " [ 120.24876  -141.99725 ]\n",
      " [ 413.03708   188.22801 ]\n",
      " [ -15.129155  -48.57789 ]\n",
      " [-126.213005   24.425646]\n",
      " [-242.94357   112.783554]\n",
      " [-283.1882    141.75974 ]\n",
      " [ -53.943424  -23.17649 ]\n",
      " [  99.13313  -126.473885]] 0.06044759999999627\n",
      "session :  5 [[-110.49078   -14.838325]\n",
      " [ 284.11444   -32.502155]\n",
      " [  47.38447   172.26665 ]\n",
      " [ 131.42108   -32.64022 ]\n",
      " [   5.31623   -27.088453]\n",
      " [ 184.41055   -34.666412]\n",
      " [ -73.920654  -21.691206]\n",
      " [ 317.564     -33.36165 ]\n",
      " [  71.14902   -30.842947]] 0.06862360000000933\n",
      "session :  6 [[ -26.776672  -66.38209 ]\n",
      " [1149.6708   -156.49503 ]\n",
      " [-634.7317    -16.825886]\n",
      " [ 345.0003    515.30505 ]\n",
      " [ 268.42508   -89.23302 ]\n",
      " [ 146.89964   -80.461716]\n",
      " [-200.673     -55.265972]\n",
      " [1037.7592   -148.11145 ]\n",
      " [ 417.96088  -104.60793 ]] 0.06617360000001327\n",
      "session :  7 [[-8.5655579e+02  4.8540333e+01]\n",
      " [ 6.9947295e+03 -1.3559441e-01]\n",
      " [-8.7727979e+02 -7.0299315e+00]\n",
      " [-8.7664990e+02 -2.7591469e+01]\n",
      " [-8.7694470e+02 -6.4505535e-01]\n",
      " [ 6.9846812e+03 -1.2628618e-01]\n",
      " [ 7.0046958e+03 -9.5479548e-02]\n",
      " [-8.7509528e+02 -1.1167489e+01]\n",
      " [-8.7823267e+02  3.8605790e+00]] 0.05008369999998763\n",
      "session :  8 [[-176.77307     27.924728 ]\n",
      " [ 930.97906     14.9107895]\n",
      " [ 126.289536   -30.282808 ]\n",
      " [-125.31656    -18.834232 ]\n",
      " [1191.5627      29.487959 ]\n",
      " [ -22.172607   -44.94543  ]\n",
      " [ 789.20734      6.1836143]\n",
      " [-179.88844     80.75518  ]\n",
      " [-178.92099    -23.152327 ]] 0.06634029999997892\n",
      "session :  9 [[-127.540695  -39.570824]\n",
      " [ 698.992    -189.44345 ]\n",
      " [ 244.72363   436.28784 ]\n",
      " [ -48.706406  -61.100006]\n",
      " [-152.75304   -22.337177]\n",
      " [ 679.3598   -184.2019  ]\n",
      " [ 222.05083   423.47495 ]\n",
      " [ -29.702412  -66.774475]\n",
      " [-150.17046   -34.20801 ]] 0.05968339999998307\n",
      "session :  11 [[-26.251469  -26.74408  ]\n",
      " [235.97705    -3.8600616]\n",
      " [-35.17426   125.96262  ]\n",
      " [376.852       3.8770723]\n",
      " [  5.896054   15.186618 ]\n",
      " [140.30174    -9.130751 ]\n",
      " [297.17844    -0.7161388]\n",
      " [-43.631767  -20.084543 ]\n",
      " [182.68004    -6.8340173]] 0.06521420000001399\n",
      "session :  12 [[-17.978518  -17.277515 ]\n",
      " [ 92.84069   -16.474953 ]\n",
      " [ -5.4841332  74.16568  ]\n",
      " [-87.562775  -65.308945 ]\n",
      " [-55.009087   47.343346 ]\n",
      " [ 18.643517    1.4707801]\n",
      " [-30.180098  -35.5062   ]\n",
      " [-21.084343   34.798447 ]\n",
      " [-74.23434    18.573015 ]] 0.07678490000006377\n",
      "session :  13 [[-161.72217     87.6974   ]\n",
      " [  22.61869    -17.918947 ]\n",
      " [ 133.045      119.99334  ]\n",
      " [ -19.190695   -32.728794 ]\n",
      " [ 168.55455    159.53648  ]\n",
      " [  97.05602     74.20259  ]\n",
      " [  47.004467    -2.3118124]\n",
      " [   4.558059   -26.881182 ]\n",
      " [  19.776      -42.40106  ]] 0.07374640000000454\n"
     ]
    }
   ],
   "source": [
    "all_centers = []\n",
    "all_time = []\n",
    "\n",
    "for freq in [6]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.reshape(data , newshape=(-1 , 768*16))\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        #自编码器的训练\n",
    "        autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "        autoencoder.fit(data , data , batch_size=32 , epochs=50 , verbose=0)\n",
    "        #encoder部分进行预测输出\n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_pca = pca.fit_transform(data_feature)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=9)\n",
    "        start = time.clock()\n",
    "        _ = kmeans.fit_transform(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        sub_centers.append(kmeans.cluster_centers_)\n",
    "        sub_time.append(time1 + time2)\n",
    "        \n",
    "        print('session : ' , session_id , kmeans.cluster_centers_ , time1 + time2)\n",
    "    \n",
    "    all_centers.append(sub_centers)\n",
    "    all_time.append(sub_time)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq :  7.5\n",
      "session :  1 [[ -9.87312     3.6735303]\n",
      " [ 47.222473    9.9345875]\n",
      " [ -6.0012875 -32.251255 ]\n",
      " [-41.74517    50.53848  ]\n",
      " [ 11.345608   -1.368478 ]\n",
      " [-17.96083   -17.609072 ]\n",
      " [-24.760798    9.858317 ]\n",
      " [-43.98355    33.16809  ]\n",
      " [ 58.452827   21.445736 ]] 0.0650976\n",
      "session :  3 [[-17.886723   -3.4190795]\n",
      " [128.0091     29.199171 ]\n",
      " [-50.723637   81.34667  ]\n",
      " [-10.601768  -28.8022   ]\n",
      " [ -1.5789691  -4.5052214]\n",
      " [-18.321884  -18.108255 ]\n",
      " [  7.612451  -36.533176 ]\n",
      " [ -2.043262  -17.930624 ]\n",
      " [115.469986   26.198242 ]] 0.06533890000000042\n",
      "session :  5 [[-11.986294  -21.178892 ]\n",
      " [-81.10913    97.48542  ]\n",
      " [129.41078    49.77595  ]\n",
      " [  8.5024    -18.102467 ]\n",
      " [ -7.3710027 -26.400063 ]\n",
      " [-18.434107  -13.721245 ]\n",
      " [  3.584116  -23.220802 ]\n",
      " [-10.763332  -28.828398 ]\n",
      " [137.37936    54.337406 ]] 0.059540400000003046\n",
      "session :  6 [[-34.49383   -21.030918 ]\n",
      " [431.41983    -2.7935557]\n",
      " [-26.628895   70.94907  ]\n",
      " [-27.152025   10.941036 ]\n",
      " [-22.708525   97.58728  ]\n",
      " [-32.84185   -15.348705 ]\n",
      " [-28.52926    -1.9190998]\n",
      " [109.18091    -5.294982 ]\n",
      " [314.97427    -4.205874 ]] 0.05942710000002194\n",
      "session :  7 [[-11.772284  -12.742622 ]\n",
      " [239.14743     2.2423747]\n",
      " [-18.266306   73.077385 ]\n",
      " [  1.4332837  17.585817 ]\n",
      " [139.84274    -3.7571084]\n",
      " [-19.258753   87.345055 ]\n",
      " [-17.46503    61.56752  ]\n",
      " [-12.469249  -18.479494 ]\n",
      " [ 61.836193   -7.8385267]] 0.058465099999978065\n",
      "session :  8 [[-27.734993   15.505516 ]\n",
      " [174.41357    -6.5589623]\n",
      " [ 31.653883   54.319218 ]\n",
      " [-25.192165  -10.053192 ]\n",
      " [147.10292   -19.381582 ]\n",
      " [121.85267   -23.448723 ]\n",
      " [-27.409214    8.295643 ]\n",
      " [-26.901417  -14.528302 ]\n",
      " [195.39587   -15.039406 ]] 0.06586559999996666\n",
      "session :  9 [[-28.461452   -2.8949687]\n",
      " [ 14.424447  -31.997717 ]\n",
      " [118.72148    11.801178 ]\n",
      " [ -9.153682   54.964222 ]\n",
      " [-28.183187   12.7193985]\n",
      " [ 29.619461  -40.604923 ]\n",
      " [  9.557137  -26.640368 ]\n",
      " [-26.624725   -7.513476 ]\n",
      " [ 20.619257  -35.816677 ]] 0.06509929999998576\n",
      "session :  11 [[114.20551      9.705716  ]\n",
      " [-14.870852    -6.807415  ]\n",
      " [-27.825048    49.905983  ]\n",
      " [ 87.699135     4.9338975 ]\n",
      " [ -0.22131969  15.194864  ]\n",
      " [-13.194669   -15.39393   ]\n",
      " [-19.155312    12.34654   ]\n",
      " [ -9.118941   -25.787085  ]\n",
      " [ -2.5820994  -13.30152   ]] 0.06802059999995436\n",
      "session :  12 [[ 3.1369061e+02  1.1786193e+01]\n",
      " [-3.0671484e+01 -1.3514587e+01]\n",
      " [-4.0563923e+01  7.4844910e+01]\n",
      " [ 2.1144725e+02  7.5937673e-02]\n",
      " [-3.6905632e+01  4.4172577e+01]\n",
      " [-2.8116617e+01 -2.4970867e+01]\n",
      " [ 2.7078830e+02  6.8330469e+00]\n",
      " [-4.4072521e+01  1.0324963e+02]\n",
      " [ 2.4614455e+02  4.0810127e+00]] 0.06521209999999655\n",
      "session :  13 [[-19.116798  -20.116507 ]\n",
      " [ 81.720764    3.1922836]\n",
      " [-27.528246   62.927128 ]\n",
      " [ 36.062595   -9.734157 ]\n",
      " [-22.994041   22.8211   ]\n",
      " [139.32455    16.85939  ]\n",
      " [-23.623934   -2.2917354]\n",
      " [106.130455    8.794844 ]\n",
      " [-14.60283   -16.114182 ]] 0.0694168000000559\n"
     ]
    }
   ],
   "source": [
    "all_centers = []\n",
    "all_time = []\n",
    "\n",
    "for freq in [7.5]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.reshape(data , newshape=(-1 , 768*16))\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        #自编码器的训练\n",
    "        autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "        autoencoder.fit(data , data , batch_size=32 , epochs=50 , verbose=0)\n",
    "        #encoder部分进行预测输出\n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_pca = pca.fit_transform(data_feature)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=9)\n",
    "        start = time.clock()\n",
    "        _ = kmeans.fit_transform(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        sub_centers.append(kmeans.cluster_centers_)\n",
    "        sub_time.append(time1 + time2)\n",
    "        \n",
    "        print('session : ' , session_id , kmeans.cluster_centers_ , time1 + time2)\n",
    "    \n",
    "    all_centers.append(sub_centers)\n",
    "    all_time.append(sub_time)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq :  8.5\n",
      "session :  1 [[ 4.16626091e+01 -7.27419043e+00]\n",
      " [-8.81259060e+00  4.77106512e-01]\n",
      " [-4.13709307e+00  2.05852242e+01]\n",
      " [-8.92675114e+00 -1.10410709e+01]\n",
      " [ 2.79053354e+00  7.46134233e+00]\n",
      " [ 4.92634048e+01 -7.32707644e+00]\n",
      " [-1.16728924e-01  3.16882057e+01]\n",
      " [-3.27077881e-02  1.99262600e+01]\n",
      " [ 1.11880831e-01 -7.77108788e-01]] 0.0693359\n",
      "session :  3 [[-1.7269699e+01 -6.8698297e+00]\n",
      " [ 8.1792099e+01 -2.1791716e+01]\n",
      " [ 2.2966099e+01  5.7645691e+01]\n",
      " [-7.7477722e+00 -5.2201295e+00]\n",
      " [-1.3762439e+01  3.5473749e-02]\n",
      " [ 2.8330486e+01  6.4688774e+01]\n",
      " [-1.8493389e+01 -2.8493943e+00]\n",
      " [ 1.7840443e+01  5.0975918e+01]\n",
      " [-1.1953937e+01 -5.9328456e+00]] 0.05515640000000133\n",
      "session :  5 [[  3.85666   -19.325634 ]\n",
      " [-47.30778    57.93997  ]\n",
      " [ 82.81519    31.265965 ]\n",
      " [-12.294344   -8.604472 ]\n",
      " [ -5.4738417 -14.84148  ]\n",
      " [ 14.027012  -14.679574 ]\n",
      " [-17.731094    1.5612825]\n",
      " [ -8.20499   -13.379711 ]\n",
      " [  9.229276  -16.37672  ]] 0.056698700000012536\n",
      "session :  6 [[-43.11992   -19.628616 ]\n",
      " [ 76.91794   -21.471546 ]\n",
      " [-12.49282    89.81831  ]\n",
      " [ 10.445333   20.51527  ]\n",
      " [118.99495   -19.620789 ]\n",
      " [-24.629486    6.6097875]\n",
      " [  3.9062674 116.033066 ]\n",
      " [-56.97757   -38.234814 ]\n",
      " [-35.753906  -12.808405 ]] 0.06054550000001768\n",
      "session :  7 [[ -0.7148516 -12.627045 ]\n",
      " [ 50.392708   20.292051 ]\n",
      " [-34.161575   34.527824 ]\n",
      " [-14.715264    3.572586 ]\n",
      " [ 23.503906   13.935067 ]\n",
      " [  4.963214   -7.24714  ]\n",
      " [ -7.433704  -14.092758 ]\n",
      " [ 14.982409    5.1109643]\n",
      " [-22.204777    8.75332  ]] 0.06557530000000611\n",
      "session :  8 [[-78.25151     2.485014 ]\n",
      " [125.08544    -2.5317266]\n",
      " [173.0649     -0.3265449]\n",
      " [-40.194614   46.786507 ]\n",
      " [-63.234833   26.070143 ]\n",
      " [-77.77131   -16.05839  ]\n",
      " [ 99.01559     1.1813121]\n",
      " [229.24042   -15.042135 ]\n",
      " [-81.03752   -31.856697 ]] 0.06073709999995458\n",
      "session :  9 [[  7.2238264 -21.930523 ]\n",
      " [-19.879984    7.593735 ]\n",
      " [ 47.5008     40.90773  ]\n",
      " [-42.428383   36.32386  ]\n",
      " [ -7.1924877   5.3428473]\n",
      " [ 69.38863    37.123577 ]\n",
      " [  1.0780998 -16.781628 ]\n",
      " [ 57.544666   24.741175 ]\n",
      " [ -4.1773415 -10.57658  ]] 0.07278710000002775\n",
      "session :  11 [[ 61.537838    7.5536237]\n",
      " [-20.144545   -4.0615034]\n",
      " [ -7.301705   58.890896 ]\n",
      " [ 22.50079   -11.691064 ]\n",
      " [  8.235605   -9.594733 ]\n",
      " [-14.762771  -10.714414 ]\n",
      " [-23.532085   62.3535   ]\n",
      " [ 81.94658    12.7362995]\n",
      " [-24.550905   43.835133 ]] 0.12091719999995121\n",
      "session :  12 [[-15.708036  -17.774233 ]\n",
      " [ 75.014885   10.757304 ]\n",
      " [-41.455643   46.751637 ]\n",
      " [ 24.945917   -7.8152633]\n",
      " [ -3.9816775  37.682858 ]\n",
      " [ -6.3620524 -16.850315 ]\n",
      " [ 14.84178    37.35523  ]\n",
      " [ 96.18144    16.794695 ]\n",
      " [-17.041538   35.1376   ]] 0.06779439999996839\n",
      "session :  13 [[ -3.7288458  44.84404  ]\n",
      " [113.08438   -47.013477 ]\n",
      " [-32.770477  -18.66106  ]\n",
      " [ 39.10271   101.125824 ]\n",
      " [136.59738   -26.733707 ]\n",
      " [-15.119462  -32.171497 ]\n",
      " [124.983795  -81.475044 ]\n",
      " [-25.311485   -5.853262 ]\n",
      " [ 83.579605  -82.59577  ]] 0.07195350000000644\n"
     ]
    }
   ],
   "source": [
    "all_centers = []\n",
    "all_time = []\n",
    "\n",
    "for freq in [8.5]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.reshape(data , newshape=(-1 , 768*16))\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        #自编码器的训练\n",
    "        autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "        autoencoder.fit(data , data , batch_size=32 , epochs=50 , verbose=0)\n",
    "        #encoder部分进行预测输出\n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_pca = pca.fit_transform(data_feature)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=9)\n",
    "        start = time.clock()\n",
    "        _ = kmeans.fit_transform(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        sub_centers.append(kmeans.cluster_centers_)\n",
    "        sub_time.append(time1 + time2)\n",
    "        \n",
    "        print('session : ' , session_id , kmeans.cluster_centers_ , time1 + time2)\n",
    "    \n",
    "    all_centers.append(sub_centers)\n",
    "    all_time.append(sub_time)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq :  10\n",
      "session :  1 [[ -9.068515   23.246708 ]\n",
      " [ 41.252605  -65.45651  ]\n",
      " [ 91.94276    40.939285 ]\n",
      " [-27.240955    4.447935 ]\n",
      " [ -5.7323856  -8.333161 ]\n",
      " [ 82.01645    59.770477 ]\n",
      " [ 98.73237    16.729208 ]\n",
      " [-22.51091    14.109867 ]\n",
      " [-12.545635  -12.969641 ]] 0.0776471\n",
      "session :  3 [[ -7.7918396 -30.853592 ]\n",
      " [ 96.57647    22.310091 ]\n",
      " [-61.742996   97.92483  ]\n",
      " [-36.985992   10.63233  ]\n",
      " [-21.580244  -27.72118  ]\n",
      " [-28.318375   -9.148458 ]\n",
      " [-66.517105   78.29668  ]\n",
      " [-16.50211   -36.615738 ]\n",
      " [ 88.72163    17.309286 ]] 0.06340709999999916\n",
      "session :  5 [[-20.02621    -6.931774 ]\n",
      " [112.02672   -53.073933 ]\n",
      " [ 62.677586   86.90036  ]\n",
      " [-25.104948   -5.0101   ]\n",
      " [-26.648825   -7.5736103]\n",
      " [-22.373419    1.7193458]\n",
      " [-28.882584   -2.8150296]\n",
      " [-16.234047   -6.357594 ]\n",
      " [ 60.232998   84.247856 ]] 0.05558020000000852\n",
      "session :  6 [[-26.85943     -7.810604  ]\n",
      " [117.498344   -24.803093  ]\n",
      " [ 36.356064    82.84787   ]\n",
      " [ 18.29755    -29.047634  ]\n",
      " [-33.809013     0.82097554]\n",
      " [134.0252     -21.526716  ]\n",
      " [ 21.794304    74.18598   ]\n",
      " [ 33.180496   102.17098   ]\n",
      " [-19.090393   -10.252472  ]] 0.0691989000000035\n",
      "session :  7 [[-32.1011      -4.097903  ]\n",
      " [200.57503     -0.8318619 ]\n",
      " [-13.746868    42.31473   ]\n",
      " [ -0.32406127  -5.0453253 ]\n",
      " [-23.645061   -11.50592   ]\n",
      " [-30.010656   -10.513469  ]\n",
      " [-33.279804     4.560942  ]\n",
      " [-16.914682    55.472923  ]\n",
      " [-27.924395    49.383305  ]] 0.06270870000000173\n",
      "session :  8 [[-14.849161  -14.193931 ]\n",
      " [ 98.59221    -2.2339766]\n",
      " [-10.096021   34.749203 ]\n",
      " [  1.6193134 -37.588776 ]\n",
      " [ -9.100639   51.200027 ]\n",
      " [-17.21815   -22.17264  ]\n",
      " [-15.325303   16.30914  ]\n",
      " [ -3.0619035 -34.402153 ]\n",
      " [-13.800437   26.135023 ]] 0.06889579999997864\n",
      "session :  9 [[-13.72959     17.337606  ]\n",
      " [ 99.520805     6.443315  ]\n",
      " [ -9.944143   -11.613471  ]\n",
      " [  9.917057   -12.029776  ]\n",
      " [-24.679344    27.749546  ]\n",
      " [-19.100164    -0.85756963]\n",
      " [-14.934691    30.066322  ]\n",
      " [-16.659494   -12.617349  ]\n",
      " [ 19.58895    -11.032073  ]] 0.06777869999996256\n",
      "session :  11 [[248.21214    -9.202986 ]\n",
      " [-34.82663     0.6845909]\n",
      " [ -6.5970445  69.83954  ]\n",
      " [-19.757746  -46.262585 ]\n",
      " [-32.177456   37.016087 ]\n",
      " [-41.374313  -20.703602 ]\n",
      " [ 14.224025   67.19927  ]\n",
      " [233.41452    -8.9832325]\n",
      " [-38.75625    -9.928063 ]] 0.06434450000006109\n",
      "session :  12 [[-11.701676   -21.62587   ]\n",
      " [118.710556    -7.035243  ]\n",
      " [-17.581924    70.367165  ]\n",
      " [-18.245178     0.39604235]\n",
      " [-19.519592    -7.905322  ]\n",
      " [125.61238     14.471295  ]\n",
      " [102.44567     16.118317  ]\n",
      " [-19.918747    10.770633  ]\n",
      " [  0.5553518  -18.308342  ]] 0.0717094999999972\n",
      "session :  13 [[-55.948177   33.311913 ]\n",
      " [466.64435    -1.3673486]\n",
      " [-64.26853   -14.731039 ]\n",
      " [-56.768543   -5.2623034]\n",
      " [-58.39093   -20.981297 ]\n",
      " [-62.326187    8.268942 ]\n",
      " [-64.25785   -29.185287 ]\n",
      " [-44.557816   39.190296 ]\n",
      " [-65.362465   -7.198721 ]] 0.05694990000000644\n"
     ]
    }
   ],
   "source": [
    "all_centers = []\n",
    "all_time = []\n",
    "\n",
    "for freq in [10]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.reshape(data , newshape=(-1 , 768*16))\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        #自编码器的训练\n",
    "        autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "        autoencoder.fit(data , data , batch_size=32 , epochs=50 , verbose=0)\n",
    "        #encoder部分进行预测输出\n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_pca = pca.fit_transform(data_feature)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=9)\n",
    "        start = time.clock()\n",
    "        _ = kmeans.fit_transform(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        sub_centers.append(kmeans.cluster_centers_)\n",
    "        sub_time.append(time1 + time2)\n",
    "        \n",
    "        print('session : ' , session_id , kmeans.cluster_centers_ , time1 + time2)\n",
    "    \n",
    "    all_centers.append(sub_centers)\n",
    "    all_time.append(sub_time)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq :  6\n",
      "session :  1 [[-12.959373  -11.963699 ]\n",
      " [ 94.549934   20.699448 ]\n",
      " [-40.848454   34.920036 ]\n",
      " [  9.242683   14.724361 ]\n",
      " [ -4.6711955 -44.606678 ]\n",
      " [  1.2790338  -6.2808604]\n",
      " [-22.9298      9.430716 ]\n",
      " [  5.6024137 -23.827173 ]\n",
      " [-55.792534   63.31543  ]] 0.029536800000002472\n",
      "session :  3 [[-16.535654  32.77816 ]\n",
      " [204.71147   -8.64754 ]\n",
      " [-36.497704 -36.34811 ]\n",
      " [-21.363096  16.501112]\n",
      " [-24.8301     3.629301]\n",
      " [-32.207108 -23.15803 ]\n",
      " [-14.362703  39.644543]\n",
      " [-37.19156  -39.953922]\n",
      " [-13.296611  43.281296]] 0.03622980000000098\n",
      "session :  5 [[-25.97834     -6.0256996 ]\n",
      " [ 80.20225     -4.2085986 ]\n",
      " [ -2.414296    62.51113   ]\n",
      " [ 23.56706     -9.9253025 ]\n",
      " [  3.9958465  -12.173977  ]\n",
      " [-20.846756   -10.971154  ]\n",
      " [ 89.92567     -3.339596  ]\n",
      " [-25.091194    -0.09492765]\n",
      " [-13.212736   -13.420394  ]] 0.06576610000001892\n",
      "session :  6 [[-24.763597    77.41472   ]\n",
      " [296.8975       0.38494703]\n",
      " [-40.305088   -10.085411  ]\n",
      " [-49.317226    27.13761   ]\n",
      " [-21.227772   -38.782265  ]\n",
      " [-50.288975    -0.9340828 ]\n",
      " [-39.34706    -17.830334  ]\n",
      " [311.67126     -1.2891705 ]\n",
      " [-34.15781    -15.272407  ]] 0.0969883000000209\n",
      "session :  7 [[-7.3392174e+01 -2.3110261e+00]\n",
      " [ 5.7224298e+02 -3.7565476e-01]\n",
      " [-6.5333717e+01  3.3636776e+01]\n",
      " [-7.2021156e+01 -5.4835052e+00]\n",
      " [-7.2797363e+01 -3.7157526e+00]\n",
      " [-7.1887260e+01 -6.4266686e+00]\n",
      " [ 5.7060681e+02 -3.3727974e-01]\n",
      " [-7.1954224e+01 -4.7570467e+00]\n",
      " [ 5.7095081e+02 -3.5496277e-01]] 0.09994670000003225\n",
      "session :  8 [[-34.043682   25.402554 ]\n",
      " [127.50518    16.544878 ]\n",
      " [-18.678118  -18.657269 ]\n",
      " [ 22.929455  -15.846988 ]\n",
      " [-38.932358   51.57663  ]\n",
      " [166.4882     28.334059 ]\n",
      " [-25.8772    -18.205822 ]\n",
      " [104.53717     9.417696 ]\n",
      " [-31.385569   -5.8543715]] 0.040271000000018375\n",
      "session :  9 [[-50.87782   -15.6481495]\n",
      " [226.53995   -53.103653 ]\n",
      " [ 66.121475  135.57336  ]\n",
      " [-46.392723  -11.735656 ]\n",
      " [-41.32529    -2.663766 ]\n",
      " [-30.700266  -24.131481 ]\n",
      " [239.16928   -54.184048 ]\n",
      " [-42.53188   -17.253613 ]\n",
      " [-37.26586     3.756523 ]] 0.032922199999973145\n",
      "session :  11 [[ 26.263977   24.361979 ]\n",
      " [-23.67252    -1.7813537]\n",
      " [ 62.070065  -40.927784 ]\n",
      " [ 76.57451    50.9321   ]\n",
      " [ 10.281099  -15.775148 ]\n",
      " [102.40848    64.18152  ]\n",
      " [-17.981995   13.968155 ]\n",
      " [ 57.14849    39.816746 ]\n",
      " [ 40.033092   30.906666 ]] 0.023396999999988566\n",
      "session :  12 [[ 43.842632  -24.349789 ]\n",
      " [-14.6451645  -0.573132 ]\n",
      " [ -1.6219957  38.27916  ]\n",
      " [-35.472786  -22.36137  ]\n",
      " [ 50.16002     8.624188 ]\n",
      " [  5.462465   -9.371832 ]\n",
      " [-22.882753    9.589369 ]\n",
      " [ 19.732136   22.252596 ]\n",
      " [ 36.426407   -4.1727057]] 0.03531810000004043\n",
      "session :  13 [[-10.095024  -19.595814 ]\n",
      " [ 98.03172    31.440546 ]\n",
      " [-54.13089    94.0122   ]\n",
      " [-35.93332    44.97757  ]\n",
      " [-65.5734    127.276764 ]\n",
      " [-12.290777   -9.456147 ]\n",
      " [ -3.2648363 -15.725172 ]\n",
      " [-48.503174   78.55093  ]\n",
      " [  0.5438859  -3.8308768]] 0.06801750000010998\n"
     ]
    }
   ],
   "source": [
    "all_centers = []\n",
    "all_time = []\n",
    "\n",
    "for freq in [6]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.reshape(data , newshape=(-1 , 768*16))\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        #自编码器的训练\n",
    "        autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "        autoencoder.fit(data , data , batch_size=32 , epochs=50 , verbose=0)\n",
    "        #encoder部分进行预测输出\n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_pca = pca.fit_transform(data_feature)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        gmm = GaussianMixture(n_components=9)\n",
    "        start = time.clock()\n",
    "        res = gmm.fit_predict(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        _centers = get_center(X_pca , res)\n",
    "        \n",
    "        sub_centers.append(_centers)\n",
    "        sub_time.append(time1 + time2)\n",
    "        \n",
    "        print('session : ' , session_id , _centers , time1 + time2)\n",
    "    \n",
    "    all_centers.append(sub_centers)\n",
    "    all_time.append(sub_time)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq :  7.5\n",
      "session :  1 [[ -8.512972   20.169722 ]\n",
      " [-19.317677   -8.179623 ]\n",
      " [ 80.95834   -33.265095 ]\n",
      " [ 24.248981   68.90833  ]\n",
      " [  1.4180418  -7.4746504]\n",
      " [-26.096544  -17.230473 ]\n",
      " [ 58.451195  -39.567272 ]\n",
      " [-19.591278    9.757782 ]\n",
      " [100.65973   -26.222055 ]] 0.0406468\n",
      "session :  3 [[-32.92987    -25.939316  ]\n",
      " [ 19.758291    40.769016  ]\n",
      " [-18.683674     8.684259  ]\n",
      " [ 75.465996     6.4753866 ]\n",
      " [ 21.194063   -39.447723  ]\n",
      " [ 40.425728   -36.163223  ]\n",
      " [ -0.65537703 -26.642065  ]\n",
      " [-23.507713     0.72828394]\n",
      " [  9.707067    43.788597  ]] 0.030296000000006984\n",
      "session :  5 [[-15.331266  -17.487284 ]\n",
      " [107.28162    10.694158 ]\n",
      " [-31.389515   66.86453  ]\n",
      " [ 13.511596   -3.7105215]\n",
      " [-23.57242     2.685237 ]\n",
      " [-21.96815   -13.344099 ]\n",
      " [  3.0172899 -11.041758 ]\n",
      " [ -7.941036  -18.044561 ]\n",
      " [  9.852599   -4.22173  ]] 0.029834999999991396\n",
      "session :  6 [[-2.52195873e+01 -6.34383559e-01]\n",
      " [ 3.93769562e+02  5.78129828e-01]\n",
      " [-3.06575012e+01  7.08211823e+01]\n",
      " [-2.90346165e+01 -1.52022295e+01]\n",
      " [-3.15275364e+01  1.03684113e+02]\n",
      " [ 2.44051208e+02 -2.59153903e-01]\n",
      " [ 6.52067947e+01 -8.98428261e-01]\n",
      " [-2.99946842e+01  5.65528183e+01]\n",
      " [-3.10700665e+01  8.99069138e+01]] 0.018595400000009477\n",
      "session :  7 [[-8.4565392e+01 -1.0656797e+01]\n",
      " [ 1.7477736e+03 -2.4985908e-01]\n",
      " [-7.7223305e+01  7.1359406e+01]\n",
      " [ 1.0933268e+03 -7.8736386e+00]\n",
      " [ 4.7892453e+02 -8.0193663e+00]\n",
      " [-7.3875046e+01  1.5086019e+01]\n",
      " [-8.1279236e+01  5.2088291e+01]\n",
      " [-7.1807281e+01 -7.9655952e+00]\n",
      " [-7.8868774e+01 -1.6371914e+01]] 0.019512100000014243\n",
      "session :  8 [[  9.941732  -44.527374 ]\n",
      " [-99.88896    58.892204 ]\n",
      " [118.67044    76.37167  ]\n",
      " [ 40.851       5.5254507]\n",
      " [-23.405746  -13.192487 ]\n",
      " [-84.26062    45.90535  ]\n",
      " [150.56226   115.49792  ]\n",
      " [104.73735    59.08013  ]\n",
      " [134.9469     99.51951  ]] 0.033547399999974914\n",
      "session :  9 [[-24.836645  -19.76516  ]\n",
      " [125.06243     6.738517 ]\n",
      " [-46.218903   74.54964  ]\n",
      " [ 70.13903    -3.1763911]\n",
      " [-29.93918     0.4070709]\n",
      " [154.1166     11.847694 ]\n",
      " [-28.823215  -14.528352 ]\n",
      " [139.24388     9.222668 ]\n",
      " [174.8641     15.507659 ]] 0.043215200000020104\n",
      "session :  11 [[-16.746819  -23.573643 ]\n",
      " [133.43996    22.172268 ]\n",
      " [-58.213673   97.95997  ]\n",
      " [  3.9680707  -1.4871068]\n",
      " [181.07933    36.85461  ]\n",
      " [ -2.9849167 -20.840479 ]\n",
      " [106.81506    13.869529 ]\n",
      " [-23.083054  -17.173777 ]\n",
      " [-19.862963  -24.405457 ]] 0.05113970000002155\n",
      "session :  12 [[   5.9821763  -79.067154 ]\n",
      " [ 264.72443    115.22906  ]\n",
      " [-162.01932    129.3508   ]\n",
      " [ -95.49734     44.83119  ]\n",
      " [ -50.137825   -13.085863 ]\n",
      " [ 358.5518     188.68347  ]\n",
      " [-237.6421     225.64922  ]\n",
      " [-192.96254    168.76704  ]\n",
      " [  40.831917   -51.13121  ]] 0.04812809999998535\n",
      "session :  13 [[-69.217705  100.410866 ]\n",
      " [336.00192    14.27528  ]\n",
      " [-42.41398   -32.02063  ]\n",
      " [ 45.51712   -18.14963  ]\n",
      " [-61.39103    32.509544 ]\n",
      " [-57.669407   -2.0324566]\n",
      " [259.55106     5.467608 ]\n",
      " [395.15466    21.108133 ]\n",
      " [300.76663    10.214051 ]] 0.04244099999993978\n"
     ]
    }
   ],
   "source": [
    "all_centers = []\n",
    "all_time = []\n",
    "\n",
    "for freq in [7.5]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.reshape(data , newshape=(-1 , 768*16))\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        #自编码器的训练\n",
    "        autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "        autoencoder.fit(data , data , batch_size=32 , epochs=50 , verbose=0)\n",
    "        #encoder部分进行预测输出\n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_pca = pca.fit_transform(data_feature)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        gmm = GaussianMixture(n_components=9)\n",
    "        start = time.clock()\n",
    "        res = gmm.fit_predict(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        _centers = get_center(X_pca , res)\n",
    "        \n",
    "        sub_centers.append(_centers)\n",
    "        sub_time.append(time1 + time2)\n",
    "        \n",
    "        print('session : ' , session_id , _centers , time1 + time2)\n",
    "    \n",
    "    all_centers.append(sub_centers)\n",
    "    all_time.append(sub_time)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq :  8.5\n",
      "session :  1 [[-16.30189   -16.760923 ]\n",
      " [ 84.87126   -12.255501 ]\n",
      " [  2.63058    24.306185 ]\n",
      " [-13.229313   33.13599  ]\n",
      " [ -6.3986206  -5.034193 ]\n",
      " [-19.411097  -18.509659 ]\n",
      " [ -8.934164    9.43967  ]\n",
      " [ 10.621984   39.409756 ]\n",
      " [-13.151014   40.87099  ]] 0.0657273\n",
      "session :  3 [[ 14.421317  -27.402388 ]\n",
      " [129.43494     9.831774 ]\n",
      " [-16.458921  -13.901213 ]\n",
      " [-26.982023   39.90481  ]\n",
      " [-25.875933   27.039536 ]\n",
      " [-20.515743   -0.6174519]\n",
      " [-22.674042  -11.931215 ]\n",
      " [-15.074618   -6.9005327]\n",
      " [-25.422686   21.809963 ]] 0.019254300000000057\n",
      "session :  5 [[ -5.004483    4.626053 ]\n",
      " [138.19461   -23.194399 ]\n",
      " [  5.8444943  90.60906  ]\n",
      " [-28.292334  -15.62281  ]\n",
      " [  5.6041484  14.781805 ]\n",
      " [-33.653484  -24.83967  ]\n",
      " [-23.787916   -9.487069 ]\n",
      " [-21.933592  -13.613951 ]\n",
      " [-29.216417   -9.843738 ]] 0.017468600000000833\n",
      "session :  6 [[-50.555244   12.83051  ]\n",
      " [ 90.46869   -72.19419  ]\n",
      " [116.832344   72.35397  ]\n",
      " [  1.1464337 -28.558325 ]\n",
      " [-35.486473    4.3531356]\n",
      " [ -5.0493584 -14.265501 ]\n",
      " [-44.672535    9.538653 ]\n",
      " [-29.957113    7.6117473]\n",
      " [  8.031374  -32.835056 ]] 0.02358330000001274\n",
      "session :  7 [[  1.2218758  -10.192783  ]\n",
      " [-38.967392    38.786343  ]\n",
      " [ 41.223915    24.463833  ]\n",
      " [-25.224344   -16.87384   ]\n",
      " [ 15.958007    -0.9683811 ]\n",
      " [ -7.5719934   -9.722356  ]\n",
      " [ -0.29492185 -13.387976  ]\n",
      " [ 11.586332    -5.996143  ]\n",
      " [ 15.387357     1.8823545 ]] 0.036404300000015155\n",
      "session :  8 [[ 383.2054      -8.752944 ]\n",
      " [-120.51169    -14.821333 ]\n",
      " [ 151.2673       1.1497182]\n",
      " [-112.428734    73.49673  ]\n",
      " [-118.87197     30.209229 ]\n",
      " [-113.66156    -34.800045 ]\n",
      " [ 366.88882      8.937114 ]\n",
      " [ 169.21268     -3.0097148]\n",
      " [ 389.46326      5.1432104]] 0.02381219999998052\n",
      "session :  9 [[-89.38356     -9.347775  ]\n",
      " [490.5026       1.8954796 ]\n",
      " [ 32.41193     -3.7222753 ]\n",
      " [-87.5727      56.42151   ]\n",
      " [ -9.953909    -6.5108027 ]\n",
      " [-68.85546     -8.802218  ]\n",
      " [ 63.365837    -3.0429308 ]\n",
      " [-86.37375    -21.23412   ]\n",
      " [-94.994354     0.58133096]] 0.023734300000000985\n",
      "session :  11 [[ -7.379212    11.103851  ]\n",
      " [ 95.09825     -0.63893616]\n",
      " [-15.0017805   -2.3979301 ]\n",
      " [-11.378403    42.614956  ]\n",
      " [ -2.9068537  -18.33602   ]\n",
      " [145.29173     -0.94116   ]\n",
      " [-19.206213   -13.65729   ]\n",
      " [  7.243792   -19.171474  ]\n",
      " [114.58853     -0.9391065 ]] 0.03596209999994926\n",
      "session :  12 [[-21.856865  -11.909801 ]\n",
      " [134.8196    -14.916964 ]\n",
      " [  6.467322   50.87452  ]\n",
      " [  1.8156836  22.161654 ]\n",
      " [ 16.321634   64.21196  ]\n",
      " [-26.713865  -10.185165 ]\n",
      " [-24.28971    -1.3712701]\n",
      " [  6.461639   49.67825  ]\n",
      " [-21.054214  -13.703214 ]] 0.07555020000000923\n",
      "session :  13 [[-19.368355    82.69858   ]\n",
      " [ -0.47022435 -24.571703  ]\n",
      " [144.16032     -5.2921324 ]\n",
      " [-27.64866     -5.3033037 ]\n",
      " [-15.912581   -13.057425  ]\n",
      " [  7.3636694   83.18055   ]\n",
      " [-25.613977   -12.873559  ]\n",
      " [-29.823196    -2.8145053 ]\n",
      " [-13.597481    -7.0262537 ]] 0.040669100000002345\n"
     ]
    }
   ],
   "source": [
    "all_centers = []\n",
    "all_time = []\n",
    "\n",
    "for freq in [8.5]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.reshape(data , newshape=(-1 , 768*16))\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        #自编码器的训练\n",
    "        autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "        autoencoder.fit(data , data , batch_size=32 , epochs=50 , verbose=0)\n",
    "        #encoder部分进行预测输出\n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_pca = pca.fit_transform(data_feature)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        gmm = GaussianMixture(n_components=9)\n",
    "        start = time.clock()\n",
    "        res = gmm.fit_predict(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        _centers = get_center(X_pca , res)\n",
    "        \n",
    "        sub_centers.append(_centers)\n",
    "        sub_time.append(time1 + time2)\n",
    "        \n",
    "        print('session : ' , session_id , _centers , time1 + time2)\n",
    "    \n",
    "    all_centers.append(sub_centers)\n",
    "    all_time.append(sub_time)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq :  10\n",
      "session :  1 [[-13.882088   -18.793104  ]\n",
      " [142.76842    -14.522353  ]\n",
      " [ -8.683321    91.89341   ]\n",
      " [-13.339914    -4.1472    ]\n",
      " [ -3.320083   -13.755402  ]\n",
      " [-22.730019   -16.889011  ]\n",
      " [-21.352863     0.37057656]\n",
      " [130.75368      5.338324  ]\n",
      " [123.78542    -16.463984  ]] 0.0240346\n",
      "session :  3 [[-10.237656  -19.52956  ]\n",
      " [ 78.91703    51.901875 ]\n",
      " [-71.39296    48.489483 ]\n",
      " [ 19.312479  -19.731384 ]\n",
      " [  0.7686747 -33.35722  ]\n",
      " [-53.855595   28.84251  ]\n",
      " [106.41902    70.90032  ]\n",
      " [ 20.36254    -4.3387566]\n",
      " [  4.3959527 -26.491623 ]] 0.017293900000005635\n",
      "session :  5 [[-20.379173   -7.413877 ]\n",
      " [ 93.4192    -22.966402 ]\n",
      " [ 27.30985    55.38455  ]\n",
      " [-10.240775    1.3109554]\n",
      " [-15.208121   -6.408049 ]\n",
      " [ -8.4163     -1.3196698]\n",
      " [-14.916953   -1.1568015]\n",
      " [-20.760885   -4.6619368]\n",
      " [-23.090208   -6.1635685]] 0.022737000000006446\n",
      "session :  6 [[ 1.1521382e+02 -4.0865746e+01]\n",
      " [-3.1899801e+01  4.3924496e-02]\n",
      " [ 5.6713497e+01  6.8642464e+01]\n",
      " [ 3.4145088e+00 -2.9257061e+01]\n",
      " [ 7.1030853e+01  6.1220959e+01]\n",
      " [ 6.5301186e+01  8.0012077e+01]\n",
      " [-2.8536438e+01 -4.1812525e+00]\n",
      " [ 1.2983038e+02 -5.1064793e+01]\n",
      " [ 6.6517281e+01  9.6772491e+01]] 0.02259100000000558\n",
      "session :  7 [[ -5.739923  -10.549155 ]\n",
      " [-12.445841   49.069542 ]\n",
      " [ 52.43153     9.534068 ]\n",
      " [ 12.192346   -4.3218884]\n",
      " [-18.704742   -1.5498338]\n",
      " [-19.90739    55.907436 ]\n",
      " [ -1.328972  -10.02381  ]\n",
      " [-10.453283  -11.369373 ]\n",
      " [-22.796282   47.633404 ]] 0.01765469999998004\n",
      "session :  8 [[-23.4251      1.9416074]\n",
      " [165.88768     3.709453 ]\n",
      " [-12.879016  -31.235807 ]\n",
      " [-26.068365   32.89937  ]\n",
      " [-17.412142   -7.4702177]\n",
      " [-24.437315   12.098556 ]\n",
      " [-13.741585  -25.52905  ]\n",
      " [-23.531525    6.3069625]\n",
      " [-17.630968  -16.9263   ]] 0.022957999999988488\n",
      "session :  9 [[ -5.844957   -2.7003014]\n",
      " [ 48.627068   -2.1125295]\n",
      " [  0.5287354  15.183461 ]\n",
      " [ -3.76366   -26.903587 ]\n",
      " [ -8.534357   30.518982 ]\n",
      " [  3.708522  -26.732975 ]\n",
      " [ -8.214319   -9.338848 ]\n",
      " [ -9.548126   -2.5378454]\n",
      " [ 59.412796    8.993058 ]] 0.015775800000000118\n",
      "session :  11 [[ 21.51912    14.926926 ]\n",
      " [-11.33054   -16.963202 ]\n",
      " [-51.382435   55.89019  ]\n",
      " [ 64.40419    20.282124 ]\n",
      " [ -3.3473873   3.3953385]\n",
      " [ -4.369804  -11.756207 ]\n",
      " [-37.013683   24.224863 ]\n",
      " [ -4.378853  -26.768282 ]\n",
      " [-42.63492    35.72215  ]] 0.016064999999969132\n",
      "session :  12 [[-16.850363    5.9066873]\n",
      " [131.61679   -16.019846 ]\n",
      " [-16.819143  -40.904823 ]\n",
      " [ -9.758872   24.0647   ]\n",
      " [132.26503    21.949808 ]\n",
      " [134.10359   -35.308296 ]\n",
      " [-19.823362   -1.564246 ]\n",
      " [-11.888161   11.450428 ]\n",
      " [124.209946   51.909637 ]] 0.05750960000000305\n",
      "session :  13 [[-14.818717  -20.036865 ]\n",
      " [187.0076      3.7259269]\n",
      " [-30.250292   15.282719 ]\n",
      " [-32.480957   44.35661  ]\n",
      " [-21.970465  -10.155631 ]\n",
      " [-29.77355     4.1047873]\n",
      " [-24.680534   10.632534 ]\n",
      " [-25.675592  -11.952908 ]\n",
      " [-17.349045  -15.8289385]] 0.06370189999995546\n"
     ]
    }
   ],
   "source": [
    "all_centers = []\n",
    "all_time = []\n",
    "\n",
    "for freq in [10]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.reshape(data , newshape=(-1 , 768*16))\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        #自编码器的训练\n",
    "        autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "        autoencoder.fit(data , data , batch_size=32 , epochs=50 , verbose=0)\n",
    "        #encoder部分进行预测输出\n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_pca = pca.fit_transform(data_feature)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        gmm = GaussianMixture(n_components=9)\n",
    "        start = time.clock()\n",
    "        res = gmm.fit_predict(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        _centers = get_center(X_pca , res)\n",
    "        \n",
    "        sub_centers.append(_centers)\n",
    "        sub_time.append(time1 + time2)\n",
    "        \n",
    "        print('session : ' , session_id , _centers , time1 + time2)\n",
    "    \n",
    "    all_centers.append(sub_centers)\n",
    "    all_time.append(sub_time)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA降维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kmeans and gmm聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense , Dropout , Conv2D , MaxPooling2D , Reshape , BatchNormalization , Flatten\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape = (256*3*16 , ))\n",
    "\n",
    "#encoder\n",
    "encoder = Dense(units=512 , activation='relu')(encoder_input)\n",
    "encoder = Dense(units=256 , activation='relu')(encoder)\n",
    "encoder = Dense(units=128 , activation='relu')(encoder)\n",
    "encoder_output = Dense(units=64 , activation='relu')(encoder) #聚类需要使用的2维特征\n",
    "\n",
    "#decoder\n",
    "decoder = Dense(units=128 , activation='relu')(encoder_output)\n",
    "decoder = Dense(units=256 , activation='relu')(decoder)\n",
    "decoder = Dense(units=512 , activation='relu')(decoder)\n",
    "decoder_output = Dense(units=256*3*16 , activation='relu')(decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(inputs=encoder_input , outputs=decoder_output)\n",
    "encoder = Model(inputs=encoder_input , outputs=encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq :  6\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'dense_8_sample_weights' with dtype float and shape [?]\n\t [[Node: dense_8_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: loss_1/mul/_1777 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_925_loss_1/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-6e4797d75bbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m#自编码器的训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;31m#encoder部分进行预测输出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mdata_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#输出2维新特征 在xOy坐标系绘制\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'dense_8_sample_weights' with dtype float and shape [?]\n\t [[Node: dense_8_sample_weights = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: loss_1/mul/_1777 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_925_loss_1/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "for freq in [6]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    sub_centers_gmm = []\n",
    "    sub_time_gmm = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.reshape(data , newshape=(-1 , 768*16))\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        #自编码器的训练\n",
    "        autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "        autoencoder.fit(data , data , batch_size=32 , epochs=50 , verbose=0)\n",
    "        #encoder部分进行预测输出\n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_lda = lda.fit_transform(data_feature , labels)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        '''\n",
    "        kmeans\n",
    "        '''\n",
    "        kmeans = KMeans(n_clusters=9)\n",
    "        start = time.clock()\n",
    "        _ = kmeans.fit_transform(X_lda)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        sub_centers.append(kmeans.cluster_centers_)\n",
    "        sub_time.append(time1 + time2)\n",
    "        \n",
    "        print('kmeans session : ' , session_id , kmeans.cluster_centers_ , time1 + time2)\n",
    "        \n",
    "        '''\n",
    "        gmm\n",
    "        '''\n",
    "        gmm = GaussianMixture(n_components=9)\n",
    "        start = time.clock()\n",
    "        res = gmm.fit_predict(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        _centers = get_center(X_pca , res)\n",
    "        \n",
    "        sub_centers.append(_centers)\n",
    "        sub_time.append(time1 + time2)\n",
    "        \n",
    "        print('gmm session : ' , session_id , _centers , time1 + time2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for freq in [7.5]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    sub_centers_gmm = []\n",
    "    sub_time_gmm = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.reshape(data , newshape=(-1 , 768*16))\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        #自编码器的训练\n",
    "        autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "        autoencoder.fit(data , data , batch_size=32 , epochs=50 , verbose=0)\n",
    "        #encoder部分进行预测输出\n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_lda = lda.fit_transform(data_feature , labels)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        '''\n",
    "        kmeans\n",
    "        '''\n",
    "        kmeans = KMeans(n_clusters=9)\n",
    "        start = time.clock()\n",
    "        _ = kmeans.fit_transform(X_lda)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        sub_centers.append(kmeans.cluster_centers_)\n",
    "        sub_time.append(time1 + time2)\n",
    "        \n",
    "        print('kmeans session : ' , session_id , kmeans.cluster_centers_ , time1 + time2)\n",
    "        \n",
    "        '''\n",
    "        gmm\n",
    "        '''\n",
    "        gmm = GaussianMixture(n_components=9)\n",
    "        start = time.clock()\n",
    "        res = gmm.fit_predict(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        _centers = get_center(X_pca , res)\n",
    "        \n",
    "        sub_centers.append(_centers)\n",
    "        sub_time.append(time1 + time2)\n",
    "        \n",
    "        print('gmm session : ' , session_id , _centers , time1 + time2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for freq in [8.5]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    sub_centers_gmm = []\n",
    "    sub_time_gmm = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.reshape(data , newshape=(-1 , 768*16))\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        #自编码器的训练\n",
    "        autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "        autoencoder.fit(data , data , batch_size=32 , epochs=50 , verbose=0)\n",
    "        #encoder部分进行预测输出\n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_lda = lda.fit_transform(data_feature , labels)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        '''\n",
    "        kmeans\n",
    "        '''\n",
    "        kmeans = KMeans(n_clusters=9)\n",
    "        start = time.clock()\n",
    "        _ = kmeans.fit_transform(X_lda)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        sub_centers.append(kmeans.cluster_centers_)\n",
    "        sub_time.append(time1 + time2)\n",
    "        \n",
    "        print('kmeans session : ' , session_id , kmeans.cluster_centers_ , time1 + time2)\n",
    "        \n",
    "        '''\n",
    "        gmm\n",
    "        '''\n",
    "        gmm = GaussianMixture(n_components=9)\n",
    "        start = time.clock()\n",
    "        res = gmm.fit_predict(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        _centers = get_center(X_pca , res)\n",
    "        \n",
    "        sub_centers.append(_centers)\n",
    "        sub_time.append(time1 + time2)\n",
    "        \n",
    "        print('gmm session : ' , session_id , _centers , time1 + time2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for freq in [10]:\n",
    "    sub_centers = []\n",
    "    sub_time = []\n",
    "    \n",
    "    sub_centers_gmm = []\n",
    "    sub_time_gmm = []\n",
    "    \n",
    "    print('freq : ' , freq)\n",
    "    \n",
    "    for session_id in [1 , 3 , 5 , 6 , 7 , 8 , 9 , 11 , 12 , 13]:\n",
    "        \n",
    "        data , labels = session_data_labels(session_id , freq , is_training=True)\n",
    "        data = np.reshape(data , newshape=(-1 , 768*16))\n",
    "        data = (data-np.mean(data)) / np.std(data)\n",
    "        \n",
    "        #自编码器的训练\n",
    "        autoencoder.compile(optimizer='adam' , loss = 'mse')\n",
    "        autoencoder.fit(data , data , batch_size=32 , epochs=50 , verbose=0)\n",
    "        #encoder部分进行预测输出\n",
    "        data_feature = encoder.predict(x = data) #输出2维新特征 在xOy坐标系绘制\n",
    "        \n",
    "        lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "        start = time.clock()\n",
    "        X_lda = lda.fit_transform(data_feature , labels)\n",
    "        time1 = time.clock() - start\n",
    "        \n",
    "        '''\n",
    "        kmeans\n",
    "        '''\n",
    "        kmeans = KMeans(n_clusters=9)\n",
    "        start = time.clock()\n",
    "        _ = kmeans.fit_transform(X_lda)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        sub_centers.append(kmeans.cluster_centers_)\n",
    "        sub_time.append(time1 + time2)\n",
    "        \n",
    "        print('kmeans session : ' , session_id , kmeans.cluster_centers_ , time1 + time2)\n",
    "        \n",
    "        '''\n",
    "        gmm\n",
    "        '''\n",
    "        gmm = GaussianMixture(n_components=9)\n",
    "        start = time.clock()\n",
    "        res = gmm.fit_predict(X_pca)\n",
    "        time2 = time.clock() - start\n",
    "        \n",
    "        _centers = get_center(X_pca , res)\n",
    "        \n",
    "        sub_centers.append(_centers)\n",
    "        sub_time.append(time1 + time2)\n",
    "        \n",
    "        print('gmm session : ' , session_id , _centers , time1 + time2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
